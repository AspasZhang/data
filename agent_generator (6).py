"""
Agentç”Ÿæˆå™¨ï¼ˆAgent Generatorï¼‰- é›†æˆæ–°æ ¼å¼å’Œæ‰¹é‡æ“ä½œ
æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œå®ç°è‡ªç”±æ¢ç´¢çš„æ•…éšœè¯Šæ–­æ•°æ®ç”Ÿæˆ
"""

import json
import time
from typing import Dict, List, Any, Optional
from datetime import datetime

from goal_extractor import GoalExtractor
from state_manager import StateManager
from enhanced_planner import EnhancedPlanner
from enhanced_world_model import EnhancedWorldModel
from tool_manager import ToolManager
from structured_output import (
    StructuredOutputGenerator,
    extract_entities_from_observation,
    should_batch_execute
)


class AgentGenerator:
    """è‡ªç”±æ¢ç´¢çš„Agentæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, tool_manager: ToolManager,
                 api_key: str,
                 api_base: str = None,
                 knowledge_base: Optional[Dict] = None,
                 max_steps: int = 20):
        """
        åˆå§‹åŒ–Agentç”Ÿæˆå™¨
        
        Args:
            tool_manager: å·¥å…·ç®¡ç†å™¨
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            knowledge_base: çŸ¥è¯†åº“
            max_steps: æœ€å¤§æ­¥éª¤æ•°
        """
        self.tool_manager = tool_manager
        self.api_key = api_key
        self.api_base = api_base or "http://10.12.208.86:8502"
        self.knowledge_base = knowledge_base
        self.max_steps = max_steps
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.goal_extractor = GoalExtractor(api_key, api_base)
        
        print("âœ… Agentç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def generate(self, 
                question: str, 
                run_config: Optional[Dict] = None,
                rewrite_question: bool = False) -> Dict[str, Any]:
        """
        ç”Ÿæˆä¸€æ¬¡è¯Šæ–­æ•°æ®ï¼ˆæ–°æ ¼å¼ï¼šquery -> response[step{cot, coa}]ï¼‰
        
        Args:
            question: é—®é¢˜æè¿°
            run_config: è¿è¡Œé…ç½®
            rewrite_question: æ˜¯å¦æ”¹å†™é—®é¢˜
            
        Returns:
            {
                "query": "é—®é¢˜",
                "response": [
                    {
                        "step1": {
                            "cot": "æ¨ç†",
                            "coa": [{"action": {...}, "observation": ...}]
                        }
                    }
                ]
            }
        """
        # é»˜è®¤é…ç½®
        if run_config is None:
            run_config = {
                "run_id": 0,
                "exploration_mode": "balanced",
                "diversity_mode": "medium",
                "temperature": 0.7
            }
        
        run_id = run_config.get('run_id', 0)
        original_question = question
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ å¼€å§‹è¿è¡Œ #{run_id + 1}")
        print(f"{'='*80}")
        
        # 0. é—®é¢˜æ”¹å†™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if rewrite_question and run_id > 0:
            print(f"ğŸ“ æ­¥éª¤0: æ”¹å†™é—®é¢˜ä»¥å¢åŠ å¤šæ ·æ€§...")
            from question_rewriter import QuestionRewriter
            
            if not hasattr(self, 'question_rewriter'):
                self.question_rewriter = QuestionRewriter(
                    api_key=self.api_key,
                    api_base=self.api_base
                )
            
            question = self.question_rewriter.rewrite_with_strategy(
                original_question,
                run_id=run_id,
                total_runs=run_config.get('total_runs', 10)
            )
            
            if question != original_question:
                print(f"   åŸå§‹: {original_question}")
                print(f"   æ”¹å†™: {question}")
            else:
                print(f"   ä¿æŒåŸé—®é¢˜")
            print()
        else:
            question = original_question
            if run_id == 0:
                print(f"é—®é¢˜: {question}")
            else:
                print(f"é—®é¢˜: {question} (æœªæ”¹å†™)")
        
        print(f"é…ç½®: exploration={run_config.get('exploration_mode')}, "
              f"diversity={run_config.get('diversity_mode')}, "
              f"temp={run_config.get('temperature')}")
        print(f"{'='*80}\n")
        
        # ============ åˆå§‹åŒ–æ–°çš„ç»“æ„åŒ–è¾“å‡ºç”Ÿæˆå™¨ ============
        output_generator = StructuredOutputGenerator()
        
        # 1. æå–ç›®æ ‡
        print("ğŸ“ æ­¥éª¤1: æå–è¯Šæ–­ç›®æ ‡...")
        goal = self.goal_extractor.extract_goals(question, knowledge_base=self.knowledge_base)
        print(f"   ä¸»è¦ç›®æ ‡: {goal.get('main_goal')}")
        print(f"   é—®é¢˜ç±»å‹: {goal.get('problem_type')}")
        print(f"   å…³é”®æ–¹é¢: {', '.join(goal.get('key_aspects', []))}")
        if goal.get('context_params'):
            print(f"   ç›¸å…³å‚æ•°: {goal.get('context_params')}")
        elif goal.get('entities'):
            print(f"   å®ä½“ä¿¡æ¯: {goal.get('entities')}")
        print()
        
        # 2. åˆå§‹åŒ–è§„åˆ’å™¨å’Œä¸–ç•Œæ¨¡å‹
        planner = EnhancedPlanner(
            tool_manager=self.tool_manager,
            api_key=self.api_key,
            api_base=self.api_base,
            exploration_mode=run_config.get('exploration_mode', 'balanced')
        )
        
        world_model = EnhancedWorldModel(
            api_key=self.api_key,
            knowledge_base=self.knowledge_base,
            api_base=self.api_base,
            diversity_mode=run_config.get('diversity_mode', 'medium')
        )
        
        # 3. åˆå§‹åŒ–çŠ¶æ€
        state = StateManager()
        
        # 4. è¿­ä»£æ¢ç´¢
        print("ğŸ” æ­¥éª¤2: å¼€å§‹è¿­ä»£æ¢ç´¢...\n")
        
        while True:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­
            should_continue, reason = state.should_continue(self.max_steps)
            
            if not should_continue:
                print(f"\nğŸ›‘ åœæ­¢æ¢ç´¢: {reason}\n")
                break
            
            step_num = state.step_count + 1
            print(f"{'â”€'*80}")
            print(f"Step {step_num}:")
            
            # ============ è·å–å·²çŸ¥å®ä½“åˆ—è¡¨ ============
            known_entities_dict = {
                'interfaces': output_generator.get_known_entities('interfaces'),
                'devices': output_generator.get_known_entities('devices')
            }
            # è¿‡æ»¤ç©ºåˆ—è¡¨
            known_entities_dict = {k: v for k, v in known_entities_dict.items() if v}
            
            # 4.1 è§„åˆ’ä¸‹ä¸€æ­¥ï¼ˆä¼ å…¥å·²çŸ¥å®ä½“ï¼‰
            plan = planner.select_next_tool(
                state, 
                goal, 
                temperature=run_config.get('temperature', 0.7),
                known_entities=known_entities_dict if known_entities_dict else None
            )
            
            if 'error' in plan:
                print(f"   âŒ è§„åˆ’å¤±è´¥: {plan['error']}")
                break
            
            # è·å–reasoningï¼ˆCoTï¼‰
            reasoning = plan.get('reasoning', '')
            print(f"   ğŸ’­ CoT: {reasoning[:100]}{'...' if len(reasoning) > 100 else ''}")
            
            # ============ å¼€å§‹æ–°çš„step ============
            output_generator.start_step(reasoning)
            
            # ============ æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡æ“ä½œ ============
            relevant_entities = self._get_relevant_entities(
                output_generator, 
                plan['tool_name']
            )
            
            if relevant_entities and len(relevant_entities) > 1 and should_batch_execute(reasoning, relevant_entities):
                # æ‰¹é‡æ“ä½œ
                print(f"   ğŸ”„ æ‰¹é‡æ“ä½œ: å¯¹ {len(relevant_entities)} ä¸ªå®ä½“æ‰§è¡Œ {plan['tool_name']}")
                
                for entity in relevant_entities:
                    # æ›´æ–°å‚æ•°
                    tool_request = self._update_tool_request_for_entity(
                        plan['tool_request'].copy(),
                        entity,
                        plan['tool_name']
                    )
                    
                    # æ‰§è¡Œå·¥å…·
                    tool_response = world_model.execute_tool(
                        plan['tool_name'],
                        tool_request,
                        context=goal.get('entities', {}),
                        run_id=run_id
                    )
                    
                    # æ·»åŠ åˆ°è¾“å‡º
                    output_generator.add_action_observation(
                        plan['tool_name'],
                        tool_request,
                        tool_response,
                        batch=True
                    )
                    
                    # æ›´æ–°çŠ¶æ€ï¼ˆåªæ·»åŠ ç¬¬ä¸€ä¸ªï¼Œé¿å…é‡å¤ï¼‰
                    if entity == relevant_entities[0]:
                        state.add_execution(
                            plan['tool_name'],
                            tool_request,
                            tool_response,
                            reasoning
                        )
                    
                    print(f"      âœ“ å¤„ç†å®ä½“: {entity}")
            
            else:
                # å•æ¬¡æ“ä½œ
                print(f"   ğŸ”§ æ‰§è¡Œå·¥å…·: {plan['tool_name']}")
                
                tool_response = world_model.execute_tool(
                    plan['tool_name'],
                    plan['tool_request'],
                    context=goal.get('entities', {}),
                    run_id=run_id
                )
                
                # æ·»åŠ åˆ°è¾“å‡º
                output_generator.add_action_observation(
                    plan['tool_name'],
                    plan['tool_request'],
                    tool_response
                )
                
                # æ›´æ–°çŠ¶æ€
                state.add_execution(
                    plan['tool_name'],
                    plan['tool_request'],
                    tool_response,
                    reasoning
                )
                
                # ============ æå–æ–°çš„å®ä½“ ============
                # å°è¯•æå–æ¥å£
                interfaces = extract_entities_from_observation(tool_response, 'interface')
                if interfaces:
                    output_generator.update_known_entities('interfaces', interfaces)
                    print(f"   ğŸ“‹ å‘ç°æ¥å£: {len(interfaces)} ä¸ª - {interfaces[:3]}{'...' if len(interfaces) > 3 else ''}")
                
                # å°è¯•æå–è®¾å¤‡
                devices = extract_entities_from_observation(tool_response, 'device')
                if devices:
                    output_generator.update_known_entities('devices', devices)
                    print(f"   ğŸ“‹ å‘ç°è®¾å¤‡: {len(devices)} ä¸ª - {devices[:3]}{'...' if len(devices) > 3 else ''}")
            
            # 4.4 åˆ†æç»“æœå¹¶æ›´æ–°è¯Šæ–­é“¾
            finding = self._analyze_tool_response(
                plan['tool_name'],
                tool_response
            )
            
            if finding:
                state.add_finding(finding['type'], finding['content'])
                print(f"   ğŸ“Œ å‘ç°: {finding['content'][:80]}{'...' if len(finding['content']) > 80 else ''}")
            
            # æ›´æ–°è¯Šæ–­é“¾
            state.update_diagnostic_chain(
                action=f"{plan['tool_name']} - {reasoning[:50]}{'...' if len(reasoning) > 50 else ''}",
                result=self._summarize_tool_result(tool_response),
                conclusion=self._generate_conclusion(tool_response, finding),
                next_focus=plan.get('next_focus', '')
            )
            
            print()
        
        # ============ æ·»åŠ æ€»ç»“æ­¥éª¤ ============
        print(f"{'â”€'*80}")
        print(f"ğŸ“ ç”Ÿæˆæ€»ç»“å’Œå¤„ç½®å»ºè®®...")
        
        summary_cot, summary_content = self._generate_summary(
            question=question,
            all_steps=output_generator.steps,
            state=state
        )
        
        # æ·»åŠ æ€»ç»“æ­¥éª¤
        output_generator.start_step(summary_cot)
        output_generator.add_action_observation(
            "summary_analysis",
            {},
            summary_content
        )
        
        print(f"   âœ… æ€»ç»“å®Œæˆ")
        print()
        
        # ============ ç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼ˆæ–°æ ¼å¼ï¼‰ ============
        result = output_generator.generate_output(question)
        
        print(f"{'='*80}")
        print(f"âœ… å®Œæˆ! æ€»å…± {len(result['response'])} æ­¥ (å«æ€»ç»“)")
        print(f"{'='*80}\n")
        
        return result
    
    def _get_relevant_entities(self, generator: StructuredOutputGenerator, tool_name: str) -> List[str]:
        """è·å–ä¸å½“å‰å·¥å…·ç›¸å…³çš„å®ä½“åˆ—è¡¨"""
        tool_name_lower = tool_name.lower()
        
        if 'interface' in tool_name_lower:
            return generator.get_known_entities('interfaces')
        elif 'device' in tool_name_lower:
            return generator.get_known_entities('devices')
        
        return []
    
    def _update_tool_request_for_entity(self, request: Dict, entity: str, tool_name: str) -> Dict:
        """æ›´æ–°å·¥å…·è¯·æ±‚å‚æ•°ä¸­çš„å®ä½“"""
        tool_name_lower = tool_name.lower()
        
        if 'interface' in tool_name_lower:
            request['interface_name'] = entity
        elif 'device' in tool_name_lower:
            request['device_name'] = entity
        
        return request
    
    def _analyze_tool_response(self, tool_name: str, response: Any) -> Optional[Dict]:
        """åˆ†æå·¥å…·å“åº”ï¼Œæå–å…³é”®å‘ç°"""
        if not response:
            return None
        
        finding = None
        
        # æ ¹æ®ä¸åŒå·¥å…·ç±»å‹åˆ†æ
        if isinstance(response, dict):
            # æ£€æŸ¥çŠ¶æ€å¼‚å¸¸
            if response.get('status') == 'down' or response.get('çŠ¶æ€') == 'down':
                finding = {
                    'type': 'anomaly',
                    'content': f"å‘ç°å¼‚å¸¸: æ¥å£çŠ¶æ€ä¸ºdown"
                }
            # æ£€æŸ¥é”™è¯¯ç»Ÿè®¡
            elif 'errors' in response or 'é”™åŒ…' in str(response):
                finding = {
                    'type': 'anomaly',
                    'content': f"å‘ç°é”™åŒ…æˆ–é”™è¯¯ç»Ÿè®¡å¼‚å¸¸"
                }
            # æ­£å¸¸æƒ…å†µ
            else:
                finding = {
                    'type': 'normal',
                    'content': "æ•°æ®è·å–æˆåŠŸï¼Œæœªå‘ç°æ˜æ˜¾å¼‚å¸¸"
                }
        
        elif isinstance(response, list):
            finding = {
                'type': 'info',
                'content': f"æˆåŠŸè·å–{len(response)}æ¡è®°å½•"
            }
        
        return finding
    
    def _summarize_tool_result(self, result: Any) -> str:
        """æ€»ç»“å·¥å…·ç»“æœï¼ˆç”¨äºè¯Šæ–­é“¾ï¼‰"""
        if isinstance(result, list):
            return f"è¿”å›{len(result)}æ¡è®°å½•"
        elif isinstance(result, dict):
            # æå–å…³é”®å­—æ®µ
            key_fields = []
            for key in ['status', 'çŠ¶æ€', 'errors', 'é”™åŒ…', 'interface', 'æ¥å£']:
                if key in result:
                    key_fields.append(f"{key}={result[key]}")
            if key_fields:
                return ", ".join(key_fields[:3])
            return "æ•°æ®è·å–æˆåŠŸ"
        return str(result)[:50]
    
    def _generate_conclusion(self, response: Any, finding: Optional[Dict]) -> str:
        """ç”Ÿæˆç»“è®º"""
        if finding:
            if finding['type'] == 'anomaly':
                return f"å‘ç°å¼‚å¸¸: {finding['content']}"
            elif finding['type'] == 'normal':
                return "æ­£å¸¸ï¼Œæ— å¼‚å¸¸"
            else:
                return finding['content']
        return "å·²æ‰§è¡Œ"
    
    def _generate_summary(self, question: str, all_steps: List[Dict], state: StateManager) -> tuple:
        """
        ç”Ÿæˆè¯Šæ–­æ€»ç»“å’Œå¤„ç½®å»ºè®®
        
        Args:
            question: åŸå§‹é—®é¢˜
            all_steps: æ‰€æœ‰æ‰§è¡Œçš„æ­¥éª¤
            state: çŠ¶æ€ç®¡ç†å™¨
            
        Returns:
            (cot, summary_content): CoTæè¿°å’Œæ€»ç»“å†…å®¹
        """
        # æ„å»ºæ€»ç»“prompt
        steps_summary = []
        for i, step_dict in enumerate(all_steps, 1):
            step_key = f"step{i}"
            if step_key in step_dict:
                step_data = step_dict[step_key]
                cot = step_data.get('cot', '')
                coa = step_data.get('coa', [])
                
                # æå–å…³é”®ä¿¡æ¯
                tools_used = [action.get('action', {}).get('name', '') for action in coa]
                steps_summary.append(f"Step {i}: {cot} (ä½¿ç”¨å·¥å…·: {', '.join(tools_used)})")
        
        # è·å–è¯Šæ–­é“¾
        diagnostic_chain = state.format_diagnostic_chain()
        
        # æ„å»ºprompt
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç½‘ç»œæ•…éšœè¯Šæ–­ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹è¯Šæ–­è¿‡ç¨‹ï¼Œç”Ÿæˆä¸€ä»½å®Œæ•´çš„æ€»ç»“åˆ†ææŠ¥å‘Šã€‚

ã€åŸå§‹é—®é¢˜ã€‘
{question}

ã€è¯Šæ–­è¿‡ç¨‹ã€‘
{chr(10).join(steps_summary)}

ã€è¯Šæ–­é“¾ã€‘
{diagnostic_chain}

è¯·ç”Ÿæˆä¸€ä»½JSONæ ¼å¼çš„æ€»ç»“æŠ¥å‘Šï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š

{{
  "æ•…éšœåˆ†æ": "ç®€è¦æè¿°å‘ç°çš„é—®é¢˜åŠå…¶åŸå› ",
  "æ ¹æœ¬åŸå› ": "åˆ†æå¯¼è‡´æ•…éšœçš„æ ¹æœ¬åŸå› ",
  "å½±å“èŒƒå›´": "æè¿°æ•…éšœçš„å½±å“èŒƒå›´",
  "å¤„ç½®å»ºè®®": "æä¾›å…·ä½“çš„ä¿®å¤æ­¥éª¤å’Œå»ºè®®",
  "é¢„é˜²æªæ–½": "å»ºè®®å¦‚ä½•é˜²æ­¢ç±»ä¼¼é—®é¢˜å†æ¬¡å‘ç”Ÿ"
}}

åªè¾“å‡ºJSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""
        
        try:
            # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
            import openai
            
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.api_base + "/v1"
            )
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1000
            )
            
            summary_text = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„markdownæ ‡è®°
            if summary_text.startswith('```json'):
                summary_text = summary_text.split('```json')[1]
            if summary_text.endswith('```'):
                summary_text = summary_text.rsplit('```', 1)[0]
            summary_text = summary_text.strip()
            
            # è§£æJSON
            import json
            summary_content = json.loads(summary_text)
            
        except Exception as e:
            print(f"   âš ï¸ æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿
            summary_content = {
                "æ•…éšœåˆ†æ": "åŸºäºè¯Šæ–­è¿‡ç¨‹ï¼Œå‘ç°äº†ç›¸å…³é—®é¢˜",
                "æ ¹æœ¬åŸå› ": "éœ€è¦è¿›ä¸€æ­¥åˆ†æç¡®å®š",
                "å½±å“èŒƒå›´": "å½±å“ç›¸å…³ç½‘ç»œè®¾å¤‡å’ŒæœåŠ¡",
                "å¤„ç½®å»ºè®®": "1. æ£€æŸ¥é…ç½®\n2. é‡å¯æœåŠ¡\n3. ç›‘æ§çŠ¶æ€",
                "é¢„é˜²æªæ–½": "å®šæœŸæ£€æŸ¥å’Œç»´æŠ¤"
            }
        
        cot = "æ€»ç»“åˆ†ææŠ¥å‘Šï¼Œå¹¶ç»™å‡ºå¤„ç½®å»ºè®®"
        
        return cot, summary_content



    def generate_batch(self,
                      question: str,
                      n_runs: int = 10,
                      output_dir: str = '/mnt/user-data/outputs/batch_runs',
                      rewrite_question: bool = False) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡ç”Ÿæˆå¤šæ¡æ•°æ®
        
        Args:
            question: é—®é¢˜æè¿°
            n_runs: è¿è¡Œæ¬¡æ•°
            output_dir: è¾“å‡ºç›®å½•
            rewrite_question: æ˜¯å¦æ”¹å†™é—®é¢˜
            
        Returns:
            æ‰€æœ‰è¿è¡Œçš„ç»“æœåˆ—è¡¨
        """
        print(f"\n{'='*80}")
        print(f"ğŸ¯ æ‰¹é‡ç”Ÿæˆ: {n_runs} æ¡æ•°æ®")
        if rewrite_question:
            print(f"ğŸ“ å¯ç”¨é—®é¢˜æ”¹å†™ä»¥å¢åŠ å¤šæ ·æ€§ï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œä½¿ç”¨åŸé—®é¢˜ï¼‰")
        print(f"{'='*80}\n")
        
        results = []
        
        for i in range(n_runs):
            # ç”Ÿæˆè¿è¡Œé…ç½®
            config = self._generate_run_config(i, n_runs)
            config['total_runs'] = n_runs
            
            # æ‰§è¡Œç”Ÿæˆ
            result = self.generate(
                question,
                config,
                rewrite_question=rewrite_question
            )
            results.append(result)
            
            # ä¿å­˜å•ä¸ªç»“æœ
            output_file = f"{output_dir}/run_{i+1:03d}.json"
            self.save_result(result, output_file)
            
            # çŸ­æš‚å»¶è¿Ÿ
            time.sleep(1)
        
        # ä¿å­˜æ±‡æ€»
        self._save_batch_summary(results, question, output_dir)
        
        return results
    
    def _generate_run_config(self, run_id: int, total_runs: int) -> Dict:
        """
        ä¸ºæ¯æ¬¡è¿è¡Œç”Ÿæˆä¸åŒçš„é…ç½®
        
        ç­–ç•¥ï¼š
        - å‰30%: greedy + low diversity
        - ä¸­40%: balanced + medium diversity
        - å30%: exploratory + high diversity
        """
        ratio = run_id / total_runs
        
        if ratio < 0.3:
            return {
                "run_id": run_id,
                "exploration_mode": "greedy",
                "diversity_mode": "low",
                "temperature": 0.5
            }
        elif ratio < 0.7:
            return {
                "run_id": run_id,
                "exploration_mode": "balanced",
                "diversity_mode": "medium",
                "temperature": 0.7
            }
        else:
            return {
                "run_id": run_id,
                "exploration_mode": "exploratory",
                "diversity_mode": "high",
                "temperature": 0.9
            }
    
    def save_result(self, result: Dict, output_file: str):
        """ä¿å­˜å•ä¸ªç»“æœ"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    
    def _save_batch_summary(self, results: List[Dict], question: str, output_dir: str):
        """ä¿å­˜æ‰¹é‡è¿è¡Œçš„æ±‡æ€»ï¼ˆé€‚é…æ–°æ ¼å¼ï¼‰"""
        
        # ä»æ–°æ ¼å¼ä¸­æå–ç»Ÿè®¡ä¿¡æ¯
        def extract_statistics(result: Dict) -> Dict:
            """ä»æ–°æ ¼å¼ä¸­æå–ç»Ÿè®¡ä¿¡æ¯"""
            steps = result.get('response', [])
            total_steps = len(steps)
            
            # ç»Ÿè®¡å·¥å…·ä½¿ç”¨
            all_tools = []
            for step_dict in steps:
                for step_key, step_data in step_dict.items():
                    coa = step_data.get('coa', [])
                    for action_obs in coa:
                        tool_name = action_obs.get('action', {}).get('name')
                        if tool_name:
                            all_tools.append(tool_name)
            
            return {
                'total_steps': total_steps,
                'total_tools': len(all_tools),
                'diagnostic_path': all_tools
            }
        
        # ä¸ºæ¯ä¸ªç»“æœæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        processed_results = []
        for i, result in enumerate(results):
            stats = extract_statistics(result)
            processed_results.append({
                'run_id': i,
                'result': result,
                'statistics': stats,
                'summary': {
                    'diagnostic_path': stats['diagnostic_path']
                }
            })
        
        # ç”Ÿæˆæ±‡æ€»
        summary = {
            "question": question,
            "total_runs": len(results),
            "timestamp": datetime.now().isoformat(),
            "statistics": {
                "avg_steps": sum(r['statistics']['total_steps'] for r in processed_results) / len(results),
                "avg_tools": sum(r['statistics']['total_tools'] for r in processed_results) / len(results),
                "step_distribution": [r['statistics']['total_steps'] for r in processed_results],
                "unique_paths": len(set(
                    tuple(r['summary']['diagnostic_path']) for r in processed_results
                ))
            },
            "runs": [
                {
                    "run_id": r['run_id'],
                    "steps": r['statistics']['total_steps'],
                    "tools": r['statistics']['total_tools'],
                    "path": r['summary']['diagnostic_path']
                }
                for r in processed_results
            ]
        }
        
        output_file = f"{output_dir}/batch_summary.json"
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ æ‰¹é‡æ±‡æ€»å·²ä¿å­˜: {output_file}")
            
            # æ‰“å°æ±‡æ€»ç»Ÿè®¡
            print(f"\n{'='*80}")
            print(f"ğŸ“Š æ‰¹é‡è¿è¡Œç»Ÿè®¡")
            print(f"{'='*80}")
            print(f"æ€»è¿è¡Œæ•°: {summary['total_runs']}")
            print(f"å¹³å‡æ­¥éª¤: {summary['statistics']['avg_steps']:.1f}")
            print(f"å¹³å‡å·¥å…·è°ƒç”¨: {summary['statistics']['avg_tools']:.1f}")
            print(f"å”¯ä¸€è·¯å¾„: {summary['statistics']['unique_paths']}")
            print(f"æ­¥éª¤åˆ†å¸ƒ: {summary['statistics']['step_distribution']}")
            print(f"{'='*80}\n")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ±‡æ€»å¤±è´¥: {e}")


if __name__ == '__main__':
    print("Agent Generator with new format and batch operations")
    print("è¯·ä½¿ç”¨ batch_generate.py è°ƒç”¨")
