"""
Agentç”Ÿæˆå™¨ï¼ˆAgent Generatorï¼‰- é›†æˆæ–°æ ¼å¼å’Œæ‰¹é‡æ“ä½œ
æ•´åˆæ‰€æœ‰ç»„ä»¶ï¼Œå®ç°è‡ªç”±æ¢ç´¢çš„æ•…éšœè¯Šæ–­æ•°æ®ç”Ÿæˆ
"""

import json
import time
from typing import Dict, List, Any, Optional
from datetime import datetime

from goal_extractor import GoalExtractor
from state_manager import StateManager
from enhanced_planner import EnhancedPlanner
from enhanced_world_model import EnhancedWorldModel
from tool_manager import ToolManager
from structured_output import (
    StructuredOutputGenerator,
    extract_entities_from_observation,
    should_batch_execute
)


class AgentGenerator:
    """è‡ªç”±æ¢ç´¢çš„Agentæ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self, tool_manager: ToolManager,
                 api_key: str,
                 api_base: str = None,
                 knowledge_base: Optional[Dict] = None,
                 max_steps: int = 20):
        """
        åˆå§‹åŒ–Agentç”Ÿæˆå™¨
        
        Args:
            tool_manager: å·¥å…·ç®¡ç†å™¨
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            knowledge_base: çŸ¥è¯†åº“
            max_steps: æœ€å¤§æ­¥éª¤æ•°
        """
        self.tool_manager = tool_manager
        self.api_key = api_key
        self.api_base = api_base or "http://10.12.208.86:8502"
        self.knowledge_base = knowledge_base
        self.max_steps = max_steps
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.goal_extractor = GoalExtractor(api_key, api_base)
        
        print("âœ… Agentç”Ÿæˆå™¨åˆå§‹åŒ–å®Œæˆ")
    
    def generate(self, 
                question: str, 
                run_config: Optional[Dict] = None,
                rewrite_question: bool = False) -> Dict[str, Any]:
        """
        ç”Ÿæˆä¸€æ¬¡è¯Šæ–­æ•°æ®ï¼ˆæ–°æ ¼å¼ï¼šquery -> response[step{cot, coa}]ï¼‰
        
        Args:
            question: é—®é¢˜æè¿°
            run_config: è¿è¡Œé…ç½®
            rewrite_question: æ˜¯å¦æ”¹å†™é—®é¢˜
            
        Returns:
            {
                "query": "é—®é¢˜",
                "response": [
                    {
                        "step1": {
                            "cot": "æ¨ç†",
                            "coa": [{"action": {...}, "observation": ...}]
                        }
                    }
                ]
            }
        """
        # é»˜è®¤é…ç½®
        if run_config is None:
            run_config = {
                "run_id": 0,
                "exploration_mode": "balanced",
                "diversity_mode": "medium",
                "temperature": 0.7
            }
        
        run_id = run_config.get('run_id', 0)
        original_question = question
        
        print(f"\n{'='*80}")
        print(f"ğŸš€ å¼€å§‹è¿è¡Œ #{run_id + 1}")
        print(f"{'='*80}")
        
        # 0. é—®é¢˜æ”¹å†™ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if rewrite_question and run_id > 0:
            print(f"ğŸ“ æ­¥éª¤0: æ”¹å†™é—®é¢˜ä»¥å¢åŠ å¤šæ ·æ€§...")
            from question_rewriter import QuestionRewriter
            
            if not hasattr(self, 'question_rewriter'):
                self.question_rewriter = QuestionRewriter(
                    api_key=self.api_key,
                    api_base=self.api_base
                )
            
            question = self.question_rewriter.rewrite_with_strategy(
                original_question,
                run_id=run_id,
                total_runs=run_config.get('total_runs', 10)
            )
            
            if question != original_question:
                print(f"   åŸå§‹: {original_question}")
                print(f"   æ”¹å†™: {question}")
            else:
                print(f"   ä¿æŒåŸé—®é¢˜")
            print()
        else:
            question = original_question
            if run_id == 0:
                print(f"é—®é¢˜: {question}")
            else:
                print(f"é—®é¢˜: {question} (æœªæ”¹å†™)")
        
        print(f"é…ç½®: exploration={run_config.get('exploration_mode')}, "
              f"diversity={run_config.get('diversity_mode')}, "
              f"temp={run_config.get('temperature')}")
        print(f"{'='*80}\n")
        
        # ============ åˆå§‹åŒ–æ–°çš„ç»“æ„åŒ–è¾“å‡ºç”Ÿæˆå™¨ ============
        output_generator = StructuredOutputGenerator()
        
        # 1. æå–ç›®æ ‡
        print("ğŸ“ æ­¥éª¤1: æå–è¯Šæ–­ç›®æ ‡...")
        goal = self.goal_extractor.extract_goals(question, knowledge_base=self.knowledge_base)
        print(f"   ä¸»è¦ç›®æ ‡: {goal.get('main_goal')}")
        print(f"   é—®é¢˜ç±»å‹: {goal.get('problem_type')}")
        print(f"   å…³é”®æ–¹é¢: {', '.join(goal.get('key_aspects', []))}")
        if goal.get('context_params'):
            print(f"   ç›¸å…³å‚æ•°: {goal.get('context_params')}")
        elif goal.get('entities'):
            print(f"   å®ä½“ä¿¡æ¯: {goal.get('entities')}")
        print()
        
        # 2. åˆå§‹åŒ–è§„åˆ’å™¨å’Œä¸–ç•Œæ¨¡å‹
        planner = EnhancedPlanner(
            tool_manager=self.tool_manager,
            api_key=self.api_key,
            api_base=self.api_base,
            exploration_mode=run_config.get('exploration_mode', 'balanced')
        )
        
        world_model = EnhancedWorldModel(
            api_key=self.api_key,
            knowledge_base=self.knowledge_base,
            api_base=self.api_base,
            diversity_mode=run_config.get('diversity_mode', 'medium')
        )
        
        # 3. åˆå§‹åŒ–çŠ¶æ€
        state = StateManager()
        
        # å¼‚å¸¸æ£€æµ‹æ ‡å¿—
        has_anomaly = False
        anomaly_steps = []  # è®°å½•åŒ…å«å¼‚å¸¸çš„æ­¥éª¤
        
        # 4. è¿­ä»£æ¢ç´¢
        print("ğŸ” æ­¥éª¤2: å¼€å§‹è¿­ä»£æ¢ç´¢...\n")
        
        while True:
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­
            should_continue, reason = state.should_continue(self.max_steps)
            
            if not should_continue:
                print(f"\nğŸ›‘ åœæ­¢æ¢ç´¢: {reason}\n")
                break
            
            step_num = state.step_count + 1
            print(f"{'â”€'*80}")
            print(f"Step {step_num}:")
            
            # æ£€æŸ¥æ˜¯å¦æ¥è¿‘æœ€å¤§æ­¥éª¤ä¸”æ²¡æœ‰å¼‚å¸¸
            approaching_limit = step_num >= self.max_steps - 2
            if approaching_limit and not has_anomaly:
                print(f"   âš ï¸  æ¥è¿‘æœ€å¤§æ­¥éª¤({self.max_steps})ä¸”æœªå‘ç°å¼‚å¸¸ï¼Œå°†å¼ºåˆ¶ç”Ÿæˆå¼‚å¸¸æ•°æ®")
            
            # ============ è·å–å·²çŸ¥å®ä½“åˆ—è¡¨ ============
            known_entities_dict = {
                'interfaces': output_generator.get_known_entities('interfaces'),
                'devices': output_generator.get_known_entities('devices')
            }
            # è¿‡æ»¤ç©ºåˆ—è¡¨
            known_entities_dict = {k: v for k, v in known_entities_dict.items() if v}
            
            # 4.1 è§„åˆ’ä¸‹ä¸€æ­¥ï¼ˆä¼ å…¥å·²çŸ¥å®ä½“ï¼‰
            plan = planner.select_next_tool(
                state, 
                goal, 
                temperature=run_config.get('temperature', 0.7),
                known_entities=known_entities_dict if known_entities_dict else None
            )
            
            if 'error' in plan:
                print(f"   âŒ è§„åˆ’å¤±è´¥: {plan['error']}")
                break
            
            # è·å–reasoningï¼ˆCoTï¼‰
            reasoning = plan.get('reasoning', '')
            print(f"   ğŸ’­ CoT: {reasoning[:100]}{'...' if len(reasoning) > 100 else ''}")
            
            # ============ å¼€å§‹æ–°çš„step ============
            output_generator.start_step(reasoning)
            
            # ============ æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡æ“ä½œ ============
            relevant_entities = self._get_relevant_entities(
                output_generator, 
                plan['tool_name']
            )
            
            if relevant_entities and len(relevant_entities) > 1 and should_batch_execute(reasoning, relevant_entities):
                # æ‰¹é‡æ“ä½œ
                print(f"   ğŸ”„ æ‰¹é‡æ“ä½œ: å¯¹ {len(relevant_entities)} ä¸ªå®ä½“æ‰§è¡Œ {plan['tool_name']}")
                
                for entity in relevant_entities:
                    # æ›´æ–°å‚æ•°
                    tool_request = self._update_tool_request_for_entity(
                        plan['tool_request'].copy(),
                        entity,
                        plan['tool_name']
                    )
                    
                    # æ‰§è¡Œå·¥å…·
                    tool_response = world_model.execute_tool(
                        plan['tool_name'],
                        tool_request,
                        context=goal.get('entities', {}),
                        run_id=run_id,
                        force_anomaly=approaching_limit and not has_anomaly
                    )
                    
                    # æ·»åŠ åˆ°è¾“å‡º
                    output_generator.add_action_observation(
                        plan['tool_name'],
                        tool_request,
                        tool_response,
                        batch=True
                    )
                    
                    # æ›´æ–°çŠ¶æ€ï¼ˆåªæ·»åŠ ç¬¬ä¸€ä¸ªï¼Œé¿å…é‡å¤ï¼‰
                    if entity == relevant_entities[0]:
                        state.add_execution(
                            plan['tool_name'],
                            tool_request,
                            tool_response,
                            reasoning
                        )
                    
                    print(f"      âœ“ å¤„ç†å®ä½“: {entity}")
            
            else:
                # å•æ¬¡æ“ä½œ
                print(f"   ğŸ”§ æ‰§è¡Œå·¥å…·: {plan['tool_name']}")
                
                tool_response = world_model.execute_tool(
                    plan['tool_name'],
                    plan['tool_request'],
                    context=goal.get('entities', {}),
                    run_id=run_id,
                    force_anomaly=approaching_limit and not has_anomaly
                )
                
                # æ·»åŠ åˆ°è¾“å‡º
                output_generator.add_action_observation(
                    plan['tool_name'],
                    plan['tool_request'],
                    tool_response
                )
                
                # æ›´æ–°çŠ¶æ€
                state.add_execution(
                    plan['tool_name'],
                    plan['tool_request'],
                    tool_response,
                    reasoning
                )
                
                # ============ æå–æ–°çš„å®ä½“ ============
                # å°è¯•æå–æ¥å£
                interfaces = extract_entities_from_observation(tool_response, 'interface')
                if interfaces:
                    output_generator.update_known_entities('interfaces', interfaces)
                    print(f"   ğŸ“‹ å‘ç°æ¥å£: {len(interfaces)} ä¸ª - {interfaces[:3]}{'...' if len(interfaces) > 3 else ''}")
                
                # å°è¯•æå–è®¾å¤‡
                devices = extract_entities_from_observation(tool_response, 'device')
                if devices:
                    output_generator.update_known_entities('devices', devices)
                    print(f"   ğŸ“‹ å‘ç°è®¾å¤‡: {len(devices)} ä¸ª - {devices[:3]}{'...' if len(devices) > 3 else ''}")
            
            # 4.4 åˆ†æç»“æœå¹¶æ›´æ–°è¯Šæ–­é“¾
            finding = self._analyze_tool_response(
                plan['tool_name'],
                tool_response
            )
            
            if finding:
                state.add_finding(finding['type'], finding['content'])
                print(f"   ğŸ“Œ å‘ç°: {finding['content'][:80]}{'...' if len(finding['content']) > 80 else ''}")
                
                # æ£€æŸ¥æ˜¯å¦å‘ç°å¼‚å¸¸
                if finding['type'] == 'anomaly':
                    has_anomaly = True
                    anomaly_steps.append(step_num)
                    print(f"   ğŸ”´ å‘ç°å¼‚å¸¸ï¼è®°å½•æ­¥éª¤ {step_num}")
            
            # æ›´æ–°è¯Šæ–­é“¾
            state.update_diagnostic_chain(
                action=f"{plan['tool_name']} - {reasoning[:50]}{'...' if len(reasoning) > 50 else ''}",
                result=self._summarize_tool_result(tool_response),
                conclusion=self._generate_conclusion(tool_response, finding),
                next_focus=plan.get('next_focus', '')
            )
            
            print()
        
        # ============ æ·»åŠ æ€»ç»“æ­¥éª¤ ============
        print(f"{'â”€'*80}")
        print(f"ğŸ“ ç”Ÿæˆæ€»ç»“å’Œå¤„ç½®å»ºè®®...")
        
        # åªä¼ é€’åŒ…å«å¼‚å¸¸çš„æ­¥éª¤ç”¨äºæ€»ç»“
        if has_anomaly:
            print(f"   ğŸ“Š ä½¿ç”¨åŒ…å«å¼‚å¸¸çš„æ­¥éª¤: {anomaly_steps}")
        else:
            print(f"   â„¹ï¸  æœªå‘ç°å¼‚å¸¸ï¼Œå°†ç”Ÿæˆæ­£å¸¸æ€»ç»“")
        
        summary_cot, summary_coa_list = self._generate_summary(
            question=question,
            all_steps=output_generator.steps,
            state=state,
            anomaly_steps=anomaly_steps if has_anomaly else None
        )
        
        # æ·»åŠ æ€»ç»“æ­¥éª¤
        output_generator.start_step(summary_cot)
        
        # æ·»åŠ æ‰€æœ‰æ£€æµ‹èŠ‚ç‚¹çš„ç»“æœ
        for coa_item in summary_coa_list:
            output_generator.add_action_observation(
                coa_item['action']['name'],
                coa_item['action']['args'],
                coa_item['observation']
            )
        
        print(f"   âœ… æ€»ç»“å®Œæˆ (åŒ…å« {len(summary_coa_list)} ä¸ªæ£€æµ‹èŠ‚ç‚¹)")
        print()
        
        # ============ ç”Ÿæˆæœ€ç»ˆè¾“å‡ºï¼ˆæ–°æ ¼å¼ï¼‰ ============
        result = output_generator.generate_output(question)
        
        print(f"{'='*80}")
        print(f"âœ… å®Œæˆ! æ€»å…± {len(result['response'])} æ­¥ (å«æ€»ç»“)")
        print(f"{'='*80}\n")
        
        return result
    
    def _get_relevant_entities(self, generator: StructuredOutputGenerator, tool_name: str) -> List[str]:
        """è·å–ä¸å½“å‰å·¥å…·ç›¸å…³çš„å®ä½“åˆ—è¡¨"""
        tool_name_lower = tool_name.lower()
        
        if 'interface' in tool_name_lower:
            return generator.get_known_entities('interfaces')
        elif 'device' in tool_name_lower:
            return generator.get_known_entities('devices')
        
        return []
    
    def _update_tool_request_for_entity(self, request: Dict, entity: str, tool_name: str) -> Dict:
        """æ›´æ–°å·¥å…·è¯·æ±‚å‚æ•°ä¸­çš„å®ä½“"""
        tool_name_lower = tool_name.lower()
        
        if 'interface' in tool_name_lower:
            request['interface_name'] = entity
        elif 'device' in tool_name_lower:
            request['device_name'] = entity
        
        return request
    
    def _analyze_tool_response(self, tool_name: str, response: Any) -> Optional[Dict]:
        """åˆ†æå·¥å…·å“åº”ï¼Œæå–å…³é”®å‘ç°"""
        if not response:
            return None
        
        finding = None
        
        # æ ¹æ®ä¸åŒå·¥å…·ç±»å‹åˆ†æ
        if isinstance(response, dict):
            # æ£€æŸ¥çŠ¶æ€å¼‚å¸¸
            if response.get('status') == 'down' or response.get('çŠ¶æ€') == 'down':
                finding = {
                    'type': 'anomaly',
                    'content': f"å‘ç°å¼‚å¸¸: æ¥å£çŠ¶æ€ä¸ºdown"
                }
            # æ£€æŸ¥é”™è¯¯ç»Ÿè®¡
            elif 'errors' in response or 'é”™åŒ…' in str(response):
                finding = {
                    'type': 'anomaly',
                    'content': f"å‘ç°é”™åŒ…æˆ–é”™è¯¯ç»Ÿè®¡å¼‚å¸¸"
                }
            # æ­£å¸¸æƒ…å†µ
            else:
                finding = {
                    'type': 'normal',
                    'content': "æ•°æ®è·å–æˆåŠŸï¼Œæœªå‘ç°æ˜æ˜¾å¼‚å¸¸"
                }
        
        elif isinstance(response, list):
            finding = {
                'type': 'info',
                'content': f"æˆåŠŸè·å–{len(response)}æ¡è®°å½•"
            }
        
        return finding
    
    def _summarize_tool_result(self, result: Any) -> str:
        """æ€»ç»“å·¥å…·ç»“æœï¼ˆç”¨äºè¯Šæ–­é“¾ï¼‰"""
        if isinstance(result, list):
            return f"è¿”å›{len(result)}æ¡è®°å½•"
        elif isinstance(result, dict):
            # æå–å…³é”®å­—æ®µ
            key_fields = []
            for key in ['status', 'çŠ¶æ€', 'errors', 'é”™åŒ…', 'interface', 'æ¥å£']:
                if key in result:
                    key_fields.append(f"{key}={result[key]}")
            if key_fields:
                return ", ".join(key_fields[:3])
            return "æ•°æ®è·å–æˆåŠŸ"
        return str(result)[:50]
    
    def _generate_conclusion(self, response: Any, finding: Optional[Dict]) -> str:
        """ç”Ÿæˆç»“è®º"""
        if finding:
            if finding['type'] == 'anomaly':
                return f"å‘ç°å¼‚å¸¸: {finding['content']}"
            elif finding['type'] == 'normal':
                return "æ­£å¸¸ï¼Œæ— å¼‚å¸¸"
            else:
                return finding['content']
        return "å·²æ‰§è¡Œ"
    
    def _generate_summary(self, question: str, all_steps: List[Dict], state: StateManager,
                         anomaly_steps: List[int] = None) -> tuple:
        """
        ç”Ÿæˆè¯Šæ–­æ€»ç»“å’Œå¤„ç½®å»ºè®®ï¼ˆåªæ€»ç»“é‡è¦èŠ‚ç‚¹ï¼‰
        
        Args:
            question: åŸå§‹é—®é¢˜
            all_steps: æ‰€æœ‰æ‰§è¡Œçš„æ­¥éª¤
            state: çŠ¶æ€ç®¡ç†å™¨
            anomaly_steps: åŒ…å«å¼‚å¸¸çš„æ­¥éª¤ç¼–å·åˆ—è¡¨ï¼ˆä»1å¼€å§‹ï¼‰
            
        Returns:
            (cot, summary_coa): CoTæè¿°å’Œæ€»ç»“å†…å®¹åˆ—è¡¨
        """
        # å¦‚æœæ²¡æœ‰å¼‚å¸¸æ­¥éª¤ï¼Œç”Ÿæˆ"æœªå‘ç°å¼‚å¸¸"çš„æ€»ç»“
        if not anomaly_steps:
            print("   â„¹ï¸  æœªå‘ç°å¼‚å¸¸ï¼Œç”Ÿæˆæ­£å¸¸æ€»ç»“")
            cot = "æ€»ç»“åˆ†ææŠ¥å‘Š"
            summary_coa = [
                {
                    "action": {
                        "name": "node_check",
                        "args": {
                            "node": "æ€»ä½“ç»“è®º",
                            "check_item": "æ•´ä½“è¯Šæ–­æ€»ç»“"
                        }
                    },
                    "observation": {
                        "çŠ¶æ€": "è¯Šæ–­å®Œæˆ",
                        "åŸå› ": f"å·²å®Œæˆ{len(all_steps)}æ­¥è¯Šæ–­æµç¨‹ï¼Œæ‰€æœ‰æ£€æµ‹é¡¹ç›®å‡æ­£å¸¸ï¼Œæœªå‘ç°å¼‚å¸¸",
                        "ä¿®å¤å»ºè®®": "ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œæ— éœ€å¤„ç†ï¼Œå»ºè®®å®šæœŸç›‘æ§"
                    }
                }
            ]
            return cot, summary_coa
        
        # åªä»å¼‚å¸¸ç›¸å…³çš„æ­¥éª¤ä¸­æå–ä¿¡æ¯
        print(f"   ğŸ“Š ä»æ­¥éª¤ {anomaly_steps} ä¸­æå–å¼‚å¸¸ä¿¡æ¯")
        
        # æ”¶é›†è¯Šæ–­è¿‡ç¨‹ä¸­çš„å…³é”®ä¿¡æ¯ï¼ˆåªä»å¼‚å¸¸æ­¥éª¤ï¼‰
        important_findings = []
        all_entities = set()
        
        # ä»stateä¸­è·å–å‘ç°çš„å¼‚å¸¸
        findings = state.findings
        
        # åªåˆ†æåŒ…å«å¼‚å¸¸çš„æ­¥éª¤
        for i, step_dict in enumerate(all_steps, 1):
            # è·³è¿‡éå¼‚å¸¸æ­¥éª¤
            if i not in anomaly_steps:
                continue
            
            step_key = f"step{i}"
            if step_key in step_dict:
                step_data = step_dict[step_key]
                coa = step_data.get('coa', [])
                
                for action_obs in coa:
                    observation = action_obs.get('observation', {})
                    
                    # æå–å®ä½“ï¼ˆè®¾å¤‡ã€æ¥å£ç­‰ï¼‰
                    if isinstance(observation, dict):
                        # æ£€æŸ¥æ˜¯å¦æœ‰å¼‚å¸¸çŠ¶æ€
                        status = observation.get('çŠ¶æ€') or observation.get('status')
                        if status and status.lower() in ['down', 'error', 'å¼‚å¸¸', 'abnormal']:
                            # è¿™æ˜¯ä¸€ä¸ªå¼‚å¸¸èŠ‚ç‚¹ï¼Œè®°å½•ä¸‹æ¥
                            entity_name = self._extract_entity_name(observation, action_obs.get('action', {}))
                            if entity_name:
                                important_findings.append({
                                    'entity': entity_name,
                                    'observation': observation,
                                    'step': i
                                })
                        
                        # è®°å½•æ‰€æœ‰å®ä½“
                        entity = self._extract_entity_name(observation, action_obs.get('action', {}))
                        if entity:
                            all_entities.add(entity)
        
        # æ„å»ºè¯Šæ–­è¿‡ç¨‹æ‘˜è¦
        execution_summary = f"è¯Šæ–­è¿‡ç¨‹å…±{len(all_steps)}æ­¥ï¼Œä»ç¬¬{anomaly_steps}æ­¥å‘ç°å¼‚å¸¸"
        
        # æ„å»ºå‘ç°æ‘˜è¦ï¼ˆfindingsæ˜¯ä¸€ä¸ªlistï¼Œä¸æ˜¯dictï¼‰
        findings_summary = ""
        if findings:  # findingsæ˜¯listï¼Œç›´æ¥åˆ¤æ–­æ˜¯å¦ä¸ºç©º
            # æå–å¼‚å¸¸ç±»å‹çš„å‘ç°
            anomalies = [f for f in findings if f.get('type') == 'anomaly']
            if anomalies:
                findings_summary += f"\nå‘ç°{len(anomalies)}ä¸ªå¼‚å¸¸ï¼š"
                for finding in anomalies[:3]:  # æœ€å¤šåˆ—3ä¸ª
                    findings_summary += f"\n  - {finding.get('content', '')}"
        
        # æ„å»ºpromptï¼ˆåªè¦æ±‚æ€»ç»“é‡è¦çš„èŠ‚ç‚¹ï¼‰
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç½‘ç»œæ•…éšœè¯Šæ–­ä¸“å®¶ã€‚è¯·åŸºäºä»¥ä¸‹è¯Šæ–­ç»“æœï¼Œç”Ÿæˆä¸€ä»½**ç®€æ´**çš„æ€»ç»“æŠ¥å‘Šã€‚

ã€åŸå§‹é—®é¢˜ã€‘
{question}

ã€è¯Šæ–­æ‘˜è¦ã€‘
{execution_summary}
{findings_summary}

ã€é‡è¦å‘ç°ã€‘
{chr(10).join([f"- {item['entity']}: {item['observation']}" for item in important_findings[:5]])}

**è¦æ±‚ï¼š**
1. **åªæ€»ç»“æœ‰é—®é¢˜æˆ–é‡è¦çš„**è®¾å¤‡/æ¥å£/IPï¼Œæ­£å¸¸çš„ä¸éœ€è¦åˆ—å‡º
2. å†…å®¹ç®€æ´ï¼Œæ¯ä¸ªèŠ‚ç‚¹çš„æè¿°ä¸è¶…è¿‡50å­—
3. å¦‚æœæ²¡æœ‰å¼‚å¸¸ï¼Œå°±åªè¿”å›æ€»ä½“ç»“è®º

è¾“å‡ºJSONæ•°ç»„æ ¼å¼ï¼š
```json
[
  {{
    "èŠ‚ç‚¹åç§°": "æœ‰é—®é¢˜çš„è®¾å¤‡/æ¥å£/IP",
    "æ£€æµ‹é¡¹": "æ£€æµ‹å†…å®¹",
    "çŠ¶æ€": "å¼‚å¸¸",
    "åŸå› ": "ç®€çŸ­è¯´æ˜åŸå› ",
    "ä¿®å¤å»ºè®®": "ç®€çŸ­çš„ä¿®å¤å»ºè®®"
  }},
  {{
    "èŠ‚ç‚¹åç§°": "æ€»ä½“ç»“è®º",
    "æ£€æµ‹é¡¹": "æ•´ä½“è¯Šæ–­æ€»ç»“",
    "çŠ¶æ€": "è¯Šæ–­å®Œæˆ",
    "åŸå› ": "ä¸»è¦é—®é¢˜æ€»ç»“",
    "ä¿®å¤å»ºè®®": "æ•´ä½“å»ºè®®"
  }}
]
```

**å¦‚æœæ‰€æœ‰èŠ‚ç‚¹éƒ½æ­£å¸¸ï¼Œåªè¿”å›æ€»ä½“ç»“è®ºä¸€ä¸ªèŠ‚ç‚¹ã€‚**
åªè¾“å‡ºJSONæ•°ç»„ï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ã€‚"""
        
        try:
            # è°ƒç”¨LLMç”Ÿæˆæ€»ç»“
            import openai
            
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.api_base + "/v1"
            )
            
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.3,
                max_tokens=1500
            )
            
            summary_text = response.choices[0].message.content.strip()
            
            # æ¸…ç†å¯èƒ½çš„markdownæ ‡è®°
            if summary_text.startswith('```json'):
                summary_text = summary_text.split('```json')[1]
            if summary_text.startswith('```'):
                summary_text = summary_text.split('```')[1]
            if summary_text.endswith('```'):
                summary_text = summary_text.rsplit('```', 1)[0]
            summary_text = summary_text.strip()
            
            # è§£æJSONæ•°ç»„
            import json
            summary_nodes = json.loads(summary_text)
            
            # é™åˆ¶èŠ‚ç‚¹æ•°é‡ï¼ˆæœ€å¤š5ä¸ªï¼ŒåŒ…å«æ€»ä½“ç»“è®ºï¼‰
            if len(summary_nodes) > 5:
                # ä¿ç•™å‰4ä¸ªé‡è¦èŠ‚ç‚¹ + æ€»ä½“ç»“è®º
                important_nodes = [n for n in summary_nodes if 'æ€»ä½“ç»“è®º' not in n.get('èŠ‚ç‚¹åç§°', '')][:4]
                conclusion_nodes = [n for n in summary_nodes if 'æ€»ä½“ç»“è®º' in n.get('èŠ‚ç‚¹åç§°', '')]
                summary_nodes = important_nodes + conclusion_nodes
            
            # è½¬æ¢ä¸ºcoaæ ¼å¼
            summary_coa = []
            for node in summary_nodes:
                summary_coa.append({
                    "action": {
                        "name": "node_check",
                        "args": {
                            "node": node.get("èŠ‚ç‚¹åç§°", "æœªçŸ¥èŠ‚ç‚¹"),
                            "check_item": node.get("æ£€æµ‹é¡¹", "")
                        }
                    },
                    "observation": {
                        "çŠ¶æ€": node.get("çŠ¶æ€", "æœªçŸ¥"),
                        "åŸå› ": node.get("åŸå› ", ""),
                        "ä¿®å¤å»ºè®®": node.get("ä¿®å¤å»ºè®®", "")
                    }
                })
            
        except Exception as e:
            print(f"   âš ï¸ æ€»ç»“ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ¨¡æ¿: {e}")
            # ä½¿ç”¨é»˜è®¤æ¨¡æ¿ï¼ˆåªæœ‰æ€»ä½“ç»“è®ºï¼‰
            summary_coa = [
                {
                    "action": {
                        "name": "node_check",
                        "args": {
                            "node": "æ€»ä½“ç»“è®º",
                            "check_item": "æ•´ä½“è¯Šæ–­æ€»ç»“"
                        }
                    },
                    "observation": {
                        "çŠ¶æ€": "è¯Šæ–­å®Œæˆ",
                        "åŸå› ": f"å·²å®Œæˆ{len(all_steps)}æ­¥è¯Šæ–­æµç¨‹",
                        "ä¿®å¤å»ºè®®": "è¯·æ ¹æ®è¯Šæ–­ç»“æœé‡‡å–ç›¸åº”æªæ–½"
                    }
                }
            ]
        
        cot = "æ€»ç»“åˆ†ææŠ¥å‘Šï¼Œå¹¶ç»™å‡ºå¤„ç½®å»ºè®®"
        
        return cot, summary_coa
    
    def _extract_entity_name(self, observation: Any, action: Dict) -> str:
        """
        ä»observationå’Œactionä¸­æå–å®ä½“åç§°
        
        Returns:
            å®ä½“åç§°ï¼Œå¦‚"è®¾å¤‡XXXçš„æ¥å£YYY"æˆ–"è®¾å¤‡XXX"
        """
        if isinstance(observation, dict):
            # å°è¯•æå–æ¥å£ä¿¡æ¯
            device = observation.get('è®¾å¤‡') or observation.get('device_name') or action.get('args', {}).get('device_name')
            interface = observation.get('æ¥å£') or observation.get('interface_name') or action.get('args', {}).get('interface_name')
            
            if device and interface:
                return f"è®¾å¤‡{device}çš„æ¥å£{interface}"
            elif interface:
                return f"æ¥å£{interface}"
            elif device:
                return f"è®¾å¤‡{device}"
            
            # å°è¯•æå–IP
            ip = observation.get('IPåœ°å€') or observation.get('ip')
            if ip:
                return f"IP {ip}"
        
        return ""



    def generate_batch(self,
                      question: str,
                      n_runs: int = 10,
                      output_dir: str = '/mnt/user-data/outputs/batch_runs',
                      rewrite_question: bool = False) -> List[Dict[str, Any]]:
        """
        æ‰¹é‡ç”Ÿæˆå¤šæ¡æ•°æ®
        
        Args:
            question: é—®é¢˜æè¿°
            n_runs: è¿è¡Œæ¬¡æ•°
            output_dir: è¾“å‡ºç›®å½•
            rewrite_question: æ˜¯å¦æ”¹å†™é—®é¢˜
            
        Returns:
            æ‰€æœ‰è¿è¡Œçš„ç»“æœåˆ—è¡¨
        """
        print(f"\n{'='*80}")
        print(f"ğŸ¯ æ‰¹é‡ç”Ÿæˆ: {n_runs} æ¡æ•°æ®")
        if rewrite_question:
            print(f"ğŸ“ å¯ç”¨é—®é¢˜æ”¹å†™ä»¥å¢åŠ å¤šæ ·æ€§ï¼ˆç¬¬ä¸€æ¬¡è¿è¡Œä½¿ç”¨åŸé—®é¢˜ï¼‰")
        print(f"{'='*80}\n")
        
        results = []
        
        for i in range(n_runs):
            # ç”Ÿæˆè¿è¡Œé…ç½®
            config = self._generate_run_config(i, n_runs)
            config['total_runs'] = n_runs
            
            # æ‰§è¡Œç”Ÿæˆ
            result = self.generate(
                question,
                config,
                rewrite_question=rewrite_question
            )
            results.append(result)
            
            # ä¿å­˜å•ä¸ªç»“æœ
            output_file = f"{output_dir}/run_{i+1:03d}.json"
            self.save_result(result, output_file)
            
            # çŸ­æš‚å»¶è¿Ÿ
            time.sleep(1)
        
        # ä¿å­˜æ±‡æ€»
        self._save_batch_summary(results, question, output_dir)
        
        return results
    
    def _generate_run_config(self, run_id: int, total_runs: int) -> Dict:
        """
        ä¸ºæ¯æ¬¡è¿è¡Œç”Ÿæˆä¸åŒçš„é…ç½®
        
        ç­–ç•¥ï¼š
        - å‰30%: greedy + low diversity
        - ä¸­40%: balanced + medium diversity
        - å30%: exploratory + high diversity
        """
        ratio = run_id / total_runs
        
        if ratio < 0.3:
            return {
                "run_id": run_id,
                "exploration_mode": "greedy",
                "diversity_mode": "low",
                "temperature": 0.5
            }
        elif ratio < 0.7:
            return {
                "run_id": run_id,
                "exploration_mode": "balanced",
                "diversity_mode": "medium",
                "temperature": 0.7
            }
        else:
            return {
                "run_id": run_id,
                "exploration_mode": "exploratory",
                "diversity_mode": "high",
                "temperature": 0.9
            }
    
    def save_result(self, result: Dict, output_file: str):
        """ä¿å­˜å•ä¸ªç»“æœ"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False, indent=2)
            print(f"ğŸ’¾ å·²ä¿å­˜: {output_file}")
        except Exception as e:
            print(f"âŒ ä¿å­˜å¤±è´¥: {e}")
    
    def _save_batch_summary(self, results: List[Dict], question: str, output_dir: str):
        """ä¿å­˜æ‰¹é‡è¿è¡Œçš„æ±‡æ€»ï¼ˆé€‚é…æ–°æ ¼å¼ï¼‰"""
        
        # ä»æ–°æ ¼å¼ä¸­æå–ç»Ÿè®¡ä¿¡æ¯
        def extract_statistics(result: Dict) -> Dict:
            """ä»æ–°æ ¼å¼ä¸­æå–ç»Ÿè®¡ä¿¡æ¯"""
            steps = result.get('response', [])
            total_steps = len(steps)
            
            # ç»Ÿè®¡å·¥å…·ä½¿ç”¨
            all_tools = []
            for step_dict in steps:
                for step_key, step_data in step_dict.items():
                    coa = step_data.get('coa', [])
                    for action_obs in coa:
                        tool_name = action_obs.get('action', {}).get('name')
                        if tool_name:
                            all_tools.append(tool_name)
            
            return {
                'total_steps': total_steps,
                'total_tools': len(all_tools),
                'diagnostic_path': all_tools
            }
        
        # ä¸ºæ¯ä¸ªç»“æœæ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        processed_results = []
        for i, result in enumerate(results):
            stats = extract_statistics(result)
            processed_results.append({
                'run_id': i,
                'result': result,
                'statistics': stats,
                'summary': {
                    'diagnostic_path': stats['diagnostic_path']
                }
            })
        
        # ç”Ÿæˆæ±‡æ€»
        summary = {
            "question": question,
            "total_runs": len(results),
            "timestamp": datetime.now().isoformat(),
            "statistics": {
                "avg_steps": sum(r['statistics']['total_steps'] for r in processed_results) / len(results),
                "avg_tools": sum(r['statistics']['total_tools'] for r in processed_results) / len(results),
                "step_distribution": [r['statistics']['total_steps'] for r in processed_results],
                "unique_paths": len(set(
                    tuple(r['summary']['diagnostic_path']) for r in processed_results
                ))
            },
            "runs": [
                {
                    "run_id": r['run_id'],
                    "steps": r['statistics']['total_steps'],
                    "tools": r['statistics']['total_tools'],
                    "path": r['summary']['diagnostic_path']
                }
                for r in processed_results
            ]
        }
        
        output_file = f"{output_dir}/batch_summary.json"
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(summary, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ æ‰¹é‡æ±‡æ€»å·²ä¿å­˜: {output_file}")
            
            # æ‰“å°æ±‡æ€»ç»Ÿè®¡
            print(f"\n{'='*80}")
            print(f"ğŸ“Š æ‰¹é‡è¿è¡Œç»Ÿè®¡")
            print(f"{'='*80}")
            print(f"æ€»è¿è¡Œæ•°: {summary['total_runs']}")
            print(f"å¹³å‡æ­¥éª¤: {summary['statistics']['avg_steps']:.1f}")
            print(f"å¹³å‡å·¥å…·è°ƒç”¨: {summary['statistics']['avg_tools']:.1f}")
            print(f"å”¯ä¸€è·¯å¾„: {summary['statistics']['unique_paths']}")
            print(f"æ­¥éª¤åˆ†å¸ƒ: {summary['statistics']['step_distribution']}")
            print(f"{'='*80}\n")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æ±‡æ€»å¤±è´¥: {e}")


if __name__ == '__main__':
    print("Agent Generator with new format and batch operations")
    print("è¯·ä½¿ç”¨ batch_generate.py è°ƒç”¨")
