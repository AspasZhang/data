"""
å¢å¼ºçš„Agent Generator - æ”¯æŒæ‰¹é‡æ“ä½œå’Œç»“æ„åŒ–è¾“å‡º
"""

import json
import sys
sys.path.insert(0, '/mnt/user-data/outputs')

from typing import Dict, List, Any, Optional
from tool_manager import ToolManager
from state_manager import StateManager
from enhanced_planner import EnhancedPlanner
from world_model import WorldModel
from structured_output import (
    StructuredOutputGenerator, 
    extract_entities_from_observation,
    should_batch_execute
)


class BatchAwareAgentGenerator:
    """æ”¯æŒæ‰¹é‡æ“ä½œçš„Agentç”Ÿæˆå™¨"""
    
    def __init__(self, 
                 tool_manager: ToolManager,
                 world_model: WorldModel,
                 api_key: str,
                 api_base: str = None,
                 model: str = "gpt-4o-mini",
                 max_steps: int = 20):
        """
        åˆå§‹åŒ–ç”Ÿæˆå™¨
        
        Args:
            tool_manager: å·¥å…·ç®¡ç†å™¨
            world_model: ä¸–ç•Œæ¨¡å‹
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
            max_steps: æœ€å¤§æ­¥éª¤æ•°
        """
        self.tool_manager = tool_manager
        self.world_model = world_model
        self.api_key = api_key
        self.api_base = api_base or "http://10.12.208.86:8502"
        self.model = model
        self.max_steps = max_steps
    
    def generate(self, question: str, knowledge_base: Dict, run_config: Dict = None) -> Dict:
        """
        ç”Ÿæˆä¸€æ¬¡è¯Šæ–­æ•°æ®ï¼ˆæ”¯æŒæ‰¹é‡æ“ä½œï¼‰
        
        Args:
            question: é—®é¢˜æè¿°
            knowledge_base: çŸ¥è¯†åº“
            run_config: è¿è¡Œé…ç½®
            
        Returns:
            ç»“æ„åŒ–è¾“å‡º
        """
        print(f"\n{'='*80}")
        print(f"å¼€å§‹ç”Ÿæˆï¼š{question}")
        print(f"{'='*80}\n")
        
        # åˆå§‹åŒ–
        output_generator = StructuredOutputGenerator()
        state = StateManager()
        planner = EnhancedPlanner(
            self.tool_manager,
            self.api_key,
            self.api_base,
            self.model
        )
        
        # æå–ç›®æ ‡
        goal = self._extract_goal(question, knowledge_base)
        
        # ä¸»å¾ªç¯
        while state.step_count < self.max_steps:
            current_step = state.step_count + 1
            print(f"{'â”€'*80}")
            print(f"Step {current_step}:")
            
            # è§„åˆ’ä¸‹ä¸€æ­¥ï¼ˆä¼ å…¥å·²çŸ¥å®ä½“ï¼‰
            known_entities_dict = {
                'interfaces': output_generator.get_known_entities('interfaces'),
                'devices': output_generator.get_known_entities('devices')
            }
            # è¿‡æ»¤ç©ºåˆ—è¡¨
            known_entities_dict = {k: v for k, v in known_entities_dict.items() if v}
            
            plan = planner.select_next_tool(
                state,
                goal,
                temperature=run_config.get('temperature', 0.7) if run_config else 0.7,
                known_entities=known_entities_dict if known_entities_dict else None
            )
            
            if 'error' in plan:
                print(f"   âŒ è§„åˆ’å¤±è´¥: {plan['error']}")
                break
            
            # è·å–reasoning
            reasoning = plan.get('reasoning', '')
            print(f"   ğŸ’­ CoT: {reasoning[:100]}...")
            
            # å¼€å§‹æ–°çš„step
            output_generator.start_step(reasoning)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦æ‰¹é‡æ“ä½œ
            known_entities = self._get_relevant_entities(output_generator, plan['tool_name'])
            
            if known_entities and len(known_entities) > 1 and should_batch_execute(reasoning, known_entities):
                # æ‰¹é‡æ“ä½œï¼šå¯¹æ¯ä¸ªå®ä½“æ‰§è¡Œç›¸åŒçš„å·¥å…·
                print(f"   ğŸ”„ æ‰¹é‡æ“ä½œ: å¯¹ {len(known_entities)} ä¸ªå®ä½“æ‰§è¡Œ {plan['tool_name']}")
                
                for entity in known_entities:
                    # æ›´æ–°è¯·æ±‚å‚æ•°ä¸­çš„å®ä½“
                    tool_request = self._update_tool_request_for_entity(
                        plan['tool_request'],
                        entity,
                        plan['tool_name']
                    )
                    
                    # æ‰§è¡Œå·¥å…·
                    tool_response = self.world_model.execute_tool(
                        plan['tool_name'],
                        tool_request,
                        context=goal.get('entities', {}),
                        run_id=f"run_{current_step}_{entity}"
                    )
                    
                    # æ·»åŠ åˆ°è¾“å‡º
                    output_generator.add_action_observation(
                        plan['tool_name'],
                        tool_request,
                        tool_response,
                        batch=True
                    )
                    
                    print(f"      âœ“ å¤„ç†å®ä½“: {entity}")
            
            else:
                # å•æ¬¡æ“ä½œ
                print(f"   ğŸ”§ æ‰§è¡Œå·¥å…·: {plan['tool_name']}")
                
                tool_response = self.world_model.execute_tool(
                    plan['tool_name'],
                    plan['tool_request'],
                    context=goal.get('entities', {}),
                    run_id=f"run_{current_step}"
                )
                
                # æ·»åŠ åˆ°è¾“å‡º
                output_generator.add_action_observation(
                    plan['tool_name'],
                    plan['tool_request'],
                    tool_response
                )
                
                # æå–æ–°çš„å®ä½“
                entities = extract_entities_from_observation(tool_response, 'interface')
                if entities:
                    output_generator.update_known_entities('interfaces', entities)
                    print(f"   ğŸ“‹ å‘ç°å®ä½“: {len(entities)} ä¸ª - {entities}")
            
            # æ›´æ–°çŠ¶æ€
            state.add_execution(
                plan['tool_name'],
                plan['tool_request'],
                tool_response,
                reasoning
            )
            
            state.update_diagnostic_chain(
                action=f"{plan['tool_name']} - {reasoning[:50]}...",
                result=self._summarize_result(tool_response),
                conclusion=self._analyze_result(tool_response),
                next_focus=plan.get('next_focus', '')
            )
            
            # æ£€æŸ¥æ˜¯å¦åº”è¯¥ç»§ç»­
            should_continue, reason = state.should_continue(self.max_steps)
            if not should_continue:
                print(f"\nğŸ›‘ åœæ­¢: {reason}")
                break
        
        # ç”Ÿæˆæœ€ç»ˆè¾“å‡º
        result = output_generator.generate_output(question)
        
        print(f"\n{'='*80}")
        print(f"âœ… å®Œæˆ! æ€»å…± {len(result['response'])} æ­¥")
        print(f"{'='*80}\n")
        
        return result
    
    def _extract_goal(self, question: str, knowledge_base: Dict) -> Dict:
        """ä»é—®é¢˜å’ŒçŸ¥è¯†åº“ä¸­æå–ç›®æ ‡"""
        # ç®€åŒ–å®ç°
        return {
            "main_goal": question,
            "problem_type": "æ•…éšœè¯Šæ–­",
            "key_aspects": ["æ¥å£çŠ¶æ€", "æ•…éšœå®šä½"],
            "entities": {},
            "context_params": {}
        }
    
    def _get_relevant_entities(self, generator: StructuredOutputGenerator, tool_name: str) -> List[str]:
        """è·å–ä¸å½“å‰å·¥å…·ç›¸å…³çš„å®ä½“åˆ—è¡¨"""
        # æ ¹æ®å·¥å…·ååˆ¤æ–­éœ€è¦ä»€ä¹ˆç±»å‹çš„å®ä½“
        if 'interface' in tool_name.lower():
            return generator.get_known_entities('interfaces')
        elif 'device' in tool_name.lower():
            return generator.get_known_entities('devices')
        return []
    
    def _update_tool_request_for_entity(self, original_request: Dict, entity: str, tool_name: str) -> Dict:
        """æ›´æ–°å·¥å…·è¯·æ±‚å‚æ•°ä¸­çš„å®ä½“"""
        request = original_request.copy()
        
        # æ ¹æ®å·¥å…·ååˆ¤æ–­åº”è¯¥æ›´æ–°å“ªä¸ªå‚æ•°
        if 'interface' in tool_name.lower():
            request['interface_name'] = entity
        elif 'device' in tool_name.lower():
            request['device_name'] = entity
        
        return request
    
    def _summarize_result(self, result: Any) -> str:
        """æ€»ç»“ç»“æœ"""
        if isinstance(result, list):
            return f"è¿”å›{len(result)}æ¡è®°å½•"
        elif isinstance(result, dict):
            keys = list(result.keys())[:3]
            return f"åŒ…å«å­—æ®µ: {', '.join(keys)}"
        return str(result)[:50]
    
    def _analyze_result(self, result: Any) -> str:
        """åˆ†æç»“æœ"""
        if isinstance(result, list):
            return f"æˆåŠŸè·å–{len(result)}æ¡æ•°æ®"
        elif isinstance(result, dict):
            if result.get('status') == 'down' or result.get('çŠ¶æ€') == 'down':
                return "å‘ç°å¼‚å¸¸ï¼šæ¥å£çŠ¶æ€ä¸ºdown"
            return "æ•°æ®è·å–æˆåŠŸ"
        return "å·²æ‰§è¡Œ"


if __name__ == '__main__':
    print("æµ‹è¯•æ‰¹é‡æ“ä½œAgent Generator")
    print("="*80 + "\n")
    
    # æ¨¡æ‹Ÿæµ‹è¯•
    print("æ³¨æ„ï¼šè¿™åªæ˜¯ç»“æ„æµ‹è¯•ï¼Œå®é™…è¿è¡Œéœ€è¦å®Œæ•´çš„ç¯å¢ƒ")
