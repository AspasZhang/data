"""
æ‰¹é‡è¿è¡Œä¸»è„šæœ¬
ç”¨äºæ‰¹é‡ç”Ÿæˆå¤šæ ·åŒ–çš„æ•…éšœè¯Šæ–­æ•°æ®
æ”¯æŒå•ä¸ªæ–‡æ¡£æˆ–å¤šä¸ªæ–‡æ¡£æ‰¹é‡å¤„ç†
"""

import sys
import json
import argparse
from pathlib import Path

# æ·»åŠ è·¯å¾„
sys.path.insert(0, '/mnt/user-data/outputs')

from tool_manager import ToolManager
from agent_generator import AgentGenerator


def load_documents_config(questions_input, knowledge_bases_input):
    """
    åŠ è½½æ–‡æ¡£é…ç½®
    
    Args:
        questions_input: é—®é¢˜å­—ç¬¦ä¸²ã€é—®é¢˜åˆ—è¡¨æ–‡ä»¶è·¯å¾„æˆ–JSONå­—ç¬¦ä¸²
        knowledge_bases_input: çŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„ã€åˆ—è¡¨æ–‡ä»¶è·¯å¾„æˆ–JSONå­—ç¬¦ä¸²
        
    Returns:
        List[Dict]: [{"question": "...", "knowledge_base": "..."}]
    """
    documents = []
    
    # å¤„ç†questions
    if questions_input.endswith('.json'):
        # ä»JSONæ–‡ä»¶åŠ è½½é—®é¢˜åˆ—è¡¨
        with open(questions_input, 'r', encoding='utf-8') as f:
            questions = json.load(f)
    elif questions_input.startswith('['):
        # ç›´æ¥è§£æJSONå­—ç¬¦ä¸²
        questions = json.loads(questions_input)
    else:
        # å•ä¸ªé—®é¢˜å­—ç¬¦ä¸²
        questions = [questions_input]
    
    # å¤„ç†knowledge_bases
    if knowledge_bases_input.endswith('.json') and Path(knowledge_bases_input).exists():
        # ä»JSONæ–‡ä»¶åŠ è½½çŸ¥è¯†åº“åˆ—è¡¨
        try:
            with open(knowledge_bases_input, 'r', encoding='utf-8') as f:
                content = f.read().strip()
                if content.startswith('['):
                    # æ˜¯ä¸€ä¸ªåˆ—è¡¨æ–‡ä»¶
                    knowledge_bases = json.loads(content)
                else:
                    # æ˜¯å•ä¸ªçŸ¥è¯†åº“æ–‡ä»¶
                    knowledge_bases = [knowledge_bases_input]
        except:
            knowledge_bases = [knowledge_bases_input]
    elif knowledge_bases_input.startswith('['):
        # ç›´æ¥è§£æJSONå­—ç¬¦ä¸²
        knowledge_bases = json.loads(knowledge_bases_input)
    else:
        # å•ä¸ªçŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„
        knowledge_bases = [knowledge_bases_input]
    
    # ç»„åˆæˆæ–‡æ¡£åˆ—è¡¨
    if len(questions) == len(knowledge_bases):
        # ä¸€å¯¹ä¸€æ˜ å°„
        for q, kb in zip(questions, knowledge_bases):
            documents.append({"question": q, "knowledge_base": kb})
    elif len(knowledge_bases) == 1:
        # æ‰€æœ‰é—®é¢˜ä½¿ç”¨åŒä¸€ä¸ªçŸ¥è¯†åº“
        for q in questions:
            documents.append({"question": q, "knowledge_base": knowledge_bases[0]})
    elif len(questions) == 1:
        # ä¸€ä¸ªé—®é¢˜ä½¿ç”¨å¤šä¸ªçŸ¥è¯†åº“ï¼ˆä¸å¤ªå¸¸è§ä½†æ”¯æŒï¼‰
        for kb in knowledge_bases:
            documents.append({"question": questions[0], "knowledge_base": kb})
    else:
        raise ValueError(f"é—®é¢˜æ•°é‡({len(questions)})å’ŒçŸ¥è¯†åº“æ•°é‡({len(knowledge_bases)})ä¸åŒ¹é…")
    
    return documents


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡ç”Ÿæˆæ•…éšœè¯Šæ–­æ•°æ® - æ”¯æŒå•ä¸ªæˆ–å¤šä¸ªæ–‡æ¡£',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹ç”¨æ³•:

1. å•ä¸ªæ–‡æ¡£:
   python3 batch_generate.py --question "é—®é¢˜æè¿°" --knowledge_base workflow.json

2. å¤šä¸ªæ–‡æ¡£ï¼ˆä»æ–‡ä»¶åŠ è½½ï¼‰:
   python3 batch_generate.py --questions questions.json --knowledge_bases kb_list.json

3. å¤šä¸ªæ–‡æ¡£ï¼ˆå‘½ä»¤è¡ŒæŒ‡å®šï¼‰:
   python3 batch_generate.py \\
     --questions '["é—®é¢˜1", "é—®é¢˜2", "é—®é¢˜3"]' \\
     --knowledge_bases '["kb1.json", "kb2.json", "kb3.json"]'

4. å¤šä¸ªé—®é¢˜å…±äº«ä¸€ä¸ªçŸ¥è¯†åº“:
   python3 batch_generate.py \\
     --questions '["é—®é¢˜1", "é—®é¢˜2"]' \\
     --knowledge_base workflow.json
        """
    )
    
    # å•ä¸ªæ–‡æ¡£å‚æ•°ï¼ˆå‘åå…¼å®¹ï¼‰
    parser.add_argument('--question', type=str, 
                       default=None,
                       help='å•ä¸ªé—®é¢˜æè¿°')
    parser.add_argument('--knowledge_base', type=str,
                       default=None,
                       help='å•ä¸ªçŸ¥è¯†åº“æ–‡ä»¶è·¯å¾„')
    
    # å¤šä¸ªæ–‡æ¡£å‚æ•°
    parser.add_argument('--questions', type=str,
                       default=None,
                       help='é—®é¢˜åˆ—è¡¨: JSONæ–‡ä»¶è·¯å¾„æˆ–JSONå­—ç¬¦ä¸² ["é—®é¢˜1", "é—®é¢˜2"]')
    parser.add_argument('--knowledge_bases', type=str,
                       default=None,
                       help='çŸ¥è¯†åº“åˆ—è¡¨: JSONæ–‡ä»¶è·¯å¾„æˆ–JSONå­—ç¬¦ä¸² ["kb1.json", "kb2.json"]')
    
    # é€šç”¨å‚æ•°
    parser.add_argument('--n_runs', type=int, default=10,
                       help='æ¯ä¸ªæ–‡æ¡£ç”Ÿæˆçš„æ•°æ®æ¡æ•°')
    parser.add_argument('--max_steps', type=int, default=20,
                       help='æ¯æ¬¡è¿è¡Œçš„æœ€å¤§æ­¥éª¤æ•°')
    parser.add_argument('--output_dir', type=str, 
                       default='/mnt/user-data/outputs/batch_runs',
                       help='åŸºç¡€è¾“å‡ºç›®å½•')
    parser.add_argument('--tools_file', type=str,
                       default='/mnt/user-data/outputs/available_tools.txt',
                       help='å·¥å…·åˆ—è¡¨æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--rewrite_question', action='store_true',
                       help='æ˜¯å¦æ”¹å†™é—®é¢˜ä»¥å¢åŠ å¤šæ ·æ€§ï¼ˆé»˜è®¤Falseï¼‰')
    
    args = parser.parse_args()
    
    # ç¡®å®šä½¿ç”¨å“ªç§æ¨¡å¼
    if args.questions or (args.question and args.questions):
        # å¤šæ–‡æ¡£æ¨¡å¼
        questions_input = args.questions or args.question
        knowledge_bases_input = args.knowledge_bases or args.knowledge_base or '/mnt/user-data/uploads/workflow.json'
    else:
        # å•æ–‡æ¡£æ¨¡å¼ï¼ˆå‘åå…¼å®¹ï¼‰
        questions_input = args.question or "serverleaf01_1_16.135è®¾å¤‡ä¸Š10GE1/0/24æ¥å£å‘ç”Ÿä¸¢åŒ…è¯¥å¦‚ä½•å¤„ç†ï¼Ÿ"
        knowledge_bases_input = args.knowledge_base or '/mnt/user-data/uploads/workflow.json'
    
    # åŠ è½½æ–‡æ¡£é…ç½®
    try:
        documents = load_documents_config(questions_input, knowledge_bases_input)
    except Exception as e:
        print(f"âŒ æ–‡æ¡£é…ç½®åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆ›å»ºåŸºç¡€è¾“å‡ºç›®å½•
    base_output_dir = Path(args.output_dir)
    base_output_dir.mkdir(parents=True, exist_ok=True)
    
    print("=" * 80)
    print("ğŸš€ æ‰¹é‡æ•°æ®ç”Ÿæˆç³»ç»Ÿ")
    print("=" * 80)
    print(f"æ–‡æ¡£æ•°é‡: {len(documents)}")
    print(f"æ¯æ–‡æ¡£ç”Ÿæˆ: {args.n_runs} æ¡")
    print(f"æœ€å¤§æ­¥éª¤: {args.max_steps}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print("=" * 80 + "\n")
    
    # åˆå§‹åŒ–å·¥å…·ç®¡ç†å™¨ï¼ˆæ‰€æœ‰æ–‡æ¡£å…±äº«ï¼‰
    print("ğŸ“‹ æ­¥éª¤1: åŠ è½½å·¥å…·åˆ—è¡¨...")
    tool_manager = ToolManager(args.tools_file)
    print(f"   âœ… å·²åŠ è½½ {len(tool_manager.tools)} ä¸ªå·¥å…·\n")
    
    # å¤„ç†æ¯ä¸ªæ–‡æ¡£
    all_results = []
    
    for doc_idx, doc in enumerate(documents, 1):
        print("\n" + "=" * 80)
        print(f"ğŸ“„ å¤„ç†æ–‡æ¡£ {doc_idx}/{len(documents)}")
        print("=" * 80)
        print(f"é—®é¢˜: {doc['question'][:80]}{'...' if len(doc['question']) > 80 else ''}")
        print(f"çŸ¥è¯†åº“: {doc['knowledge_base']}")
        print("=" * 80 + "\n")
        
        # ä¸ºå½“å‰æ–‡æ¡£åˆ›å»ºè¾“å‡ºç›®å½•
        if len(documents) > 1:
            doc_output_dir = base_output_dir / f"doc_{doc_idx:03d}"
        else:
            doc_output_dir = base_output_dir
        doc_output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½çŸ¥è¯†åº“
        print(f"ğŸ“š åŠ è½½çŸ¥è¯†åº“...")
        try:
            with open(doc['knowledge_base'], 'r', encoding='utf-8') as f:
                knowledge_base = json.load(f)
            print(f"   âœ… å·²åŠ è½½çŸ¥è¯†åº“: {doc['knowledge_base']}\n")
        except Exception as e:
            print(f"   âš ï¸  çŸ¥è¯†åº“åŠ è½½å¤±è´¥: {e}")
            print(f"   â„¹ï¸  å°†ä½¿ç”¨é»˜è®¤é…ç½®\n")
            knowledge_base = {}
        
        # åˆ›å»ºç”Ÿæˆå™¨
        print("ğŸ¤– åˆå§‹åŒ–Agentç”Ÿæˆå™¨...")
        generator = AgentGenerator(
            tool_manager=tool_manager,
            api_key="kw-qIdb2KBfLLBkk6YEJ1clWKKOctnHgWMjtfRJwQ2yTLBCXjMv",
            api_base="http://10.12.208.86:8502",
            knowledge_base=knowledge_base,
            max_steps=args.max_steps
        )
        print()
        
        # æ‰¹é‡ç”Ÿæˆ
        print(f"ğŸ”„ å¼€å§‹ç”Ÿæˆ {args.n_runs} æ¡æ•°æ®...")
        print("-" * 80 + "\n")
        
        try:
            results = generator.generate_batch(
                question=doc['question'],
                n_runs=args.n_runs,
                output_dir=str(doc_output_dir),
                rewrite_question=args.rewrite_question
            )
            
            all_results.append({
                "doc_id": doc_idx,
                "question": doc['question'],
                "knowledge_base": doc['knowledge_base'],
                "output_dir": str(doc_output_dir),
                "results": results
            })
            
            # æ˜¾ç¤ºå½“å‰æ–‡æ¡£ç»Ÿè®¡
            print("\n" + "=" * 80)
            print(f"âœ… æ–‡æ¡£ {doc_idx} ç”Ÿæˆå®Œæˆï¼")
            print("=" * 80)
            print(f"è¾“å‡ºç›®å½•: {doc_output_dir}")
            print(f"ç”Ÿæˆæ–‡ä»¶:")
            print(f"  - å•æ¬¡è¿è¡Œ: run_*.json ({args.n_runs}ä¸ª)")
            print(f"  - æ‰¹é‡æ±‡æ€»: batch_summary.json")
            
            # è·¯å¾„å¤šæ ·æ€§åˆ†æ
            paths = [tuple(r['summary']['diagnostic_path']) for r in results]
            unique_paths = len(set(paths))
            
            print(f"\nğŸ“Š è·¯å¾„å¤šæ ·æ€§:")
            print(f"  æ€»è¿è¡Œæ•°: {len(results)}")
            print(f"  å”¯ä¸€è·¯å¾„: {unique_paths}")
            print(f"  å¤šæ ·æ€§æ¯”ä¾‹: {unique_paths/len(results)*100:.1f}%")
            
            # æ˜¾ç¤ºå‰3æ¡è·¯å¾„
            if len(results) > 0:
                print(f"\nå‰3æ¡è·¯å¾„ç¤ºä¾‹:")
                for i, result in enumerate(results[:3], 1):
                    path = result['summary']['diagnostic_path']
                    steps = len(path)
                    print(f"  Run {i} ({steps}æ­¥): {' â†’ '.join(path[:5])}" + 
                          (f" â†’ ..." if steps > 5 else ""))
            
            print("=" * 80)
            
        except Exception as e:
            print(f"\nâŒ æ–‡æ¡£ {doc_idx} ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
    
    # æœ€ç»ˆæ±‡æ€»
    print("\n\n" + "=" * 80)
    print("ğŸ‰ æ‰€æœ‰æ–‡æ¡£å¤„ç†å®Œæˆï¼")
    print("=" * 80)
    print(f"æ€»æ–‡æ¡£æ•°: {len(documents)}")
    print(f"æˆåŠŸå¤„ç†: {len(all_results)}")
    print(f"æ¯æ–‡æ¡£ç”Ÿæˆ: {args.n_runs} æ¡")
    print(f"æ€»æ•°æ®æ¡æ•°: {len(all_results) * args.n_runs}")
    
    # ä¿å­˜æ€»ä½“æ±‡æ€»
    if len(documents) > 1:
        summary_file = base_output_dir / "all_documents_summary.json"
        summary_data = {
            "total_documents": len(documents),
            "n_runs_per_doc": args.n_runs,
            "max_steps": args.max_steps,
            "documents": [
                {
                    "doc_id": r["doc_id"],
                    "question": r["question"],
                    "output_dir": r["output_dir"],
                    "total_runs": len(r["results"]),
                    "avg_steps": sum(res['statistics']['total_steps'] for res in r["results"]) / len(r["results"]),
                    "unique_paths": len(set(tuple(res['summary']['diagnostic_path']) for res in r["results"]))
                }
                for r in all_results
            ]
        }
        
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary_data, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ æ€»ä½“æ±‡æ€»å·²ä¿å­˜: {summary_file}")
    
    print("\n" + "=" * 80)


if __name__ == '__main__':
    main()
