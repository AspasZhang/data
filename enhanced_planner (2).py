"""
å¢å¼ºè§„åˆ’å™¨ï¼ˆEnhanced Plannerï¼‰
æ”¯æŒè‡ªç”±æ¢ç´¢å’Œå¤šæ ·åŒ–çš„å·¥å…·é€‰æ‹©ç­–ç•¥
"""

import json
import openai
import random
from typing import Dict, List, Any, Optional
from tool_manager import ToolManager
from state_manager import StateManager


class EnhancedPlanner:
    """å¢å¼ºè§„åˆ’å™¨ - æ”¯æŒå¤šæ ·åŒ–æ¢ç´¢"""
    
    def __init__(self, tool_manager: ToolManager, 
                 api_key: str, 
                 api_base: str = None,
                 model: str = "gpt-4o-mini",
                 exploration_mode: str = 'balanced'):
        """
        åˆå§‹åŒ–å¢å¼ºè§„åˆ’å™¨
        
        Args:
            tool_manager: å·¥å…·ç®¡ç†å™¨
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
            exploration_mode: æ¢ç´¢æ¨¡å¼ ('greedy', 'balanced', 'exploratory')
        """
        self.tool_manager = tool_manager
        self.api_key = api_key
        self.api_base = api_base or "http://10.12.208.86:8502"
        self.model = model
        self.exploration_mode = exploration_mode
    
    def select_next_tool(self, state: StateManager, goal: Dict[str, Any], 
                        temperature: float = 0.7) -> Dict[str, Any]:
        """
        é€‰æ‹©ä¸‹ä¸€æ­¥è¦ä½¿ç”¨çš„å·¥å…·
        
        Args:
            state: å½“å‰çŠ¶æ€
            goal: è¯Šæ–­ç›®æ ‡
            temperature: æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰
            
        Returns:
            {
                "tool_name": "å·¥å…·åç§°",
                "tool_request": {...},
                "reasoning": "é€‰æ‹©ç†ç”±",
                "expected_info": "æœŸæœ›ä¿¡æ¯"
            }
        """
        # 1. ç”Ÿæˆprompt
        prompt = self._generate_planning_prompt(state, goal)
        
        # 2. è°ƒç”¨LLMè·å–å€™é€‰å·¥å…·
        candidates = self._get_tool_candidates(prompt, temperature, top_k=3)
        
        if not candidates:
            return {"error": "æœªèƒ½ç”Ÿæˆå·¥å…·é€‰æ‹©"}
        
        # 3. åº”ç”¨explorationç­–ç•¥é€‰æ‹©æœ€ç»ˆå·¥å…·
        selected = self._apply_exploration_strategy(candidates, state)
        
        return selected
    
    def _generate_planning_prompt(self, state: StateManager, goal: Dict[str, Any]) -> str:
        """ç”Ÿæˆè§„åˆ’prompt"""
        
        # è·å–å¯ç”¨å·¥å…·åˆ—è¡¨
        available_tools = self.tool_manager.get_tools_compact_list()
        
        # æ ¼å¼åŒ–å·²æ‰§è¡Œçš„å·¥å…·
        history = state.format_recent_history(n=5)
        
        # æ ¼å¼åŒ–è§‚å¯Ÿç»“æœ
        observations = state.format_observations()
        
        # æ ¼å¼åŒ–å‘ç°
        findings = state.format_findings()
        
        # å·²ä½¿ç”¨çš„å·¥å…·ï¼ˆç”¨äºå‚è€ƒï¼‰
        used_tools = list(state.tool_usage_count.keys())
        
        # æå–context_paramsï¼ˆä»mock_dataæå–çš„å‚æ•°ï¼‰
        context_params = goal.get('context_params', {})
        
        # å¦‚æœæœ‰context_paramsï¼Œæ ¼å¼åŒ–å±•ç¤º
        params_section = ""
        if context_params:
            params_section = self._format_context_params(context_params)
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç½‘ç»œæ•…éšœè¯Šæ–­ä¸“å®¶ï¼Œæ­£åœ¨è¿›è¡Œæ•…éšœæ’æŸ¥ã€‚

ã€è¯Šæ–­ç›®æ ‡ã€‘
ä¸»è¦ç›®æ ‡: {goal.get('main_goal', 'æœªçŸ¥')}
é—®é¢˜ç±»å‹: {goal.get('problem_type', 'æœªçŸ¥')}
éœ€è¦å…³æ³¨çš„æ–¹é¢: {', '.join(goal.get('key_aspects', []))}

{params_section}

ã€å·²æ‰§è¡Œçš„æ­¥éª¤ã€‘ï¼ˆæœ€è¿‘5æ­¥ï¼‰
{history}

ã€å½“å‰è§‚å¯Ÿç»“æœã€‘
{observations}

ã€å½“å‰å‘ç°ã€‘
{findings}

ã€å·²ä½¿ç”¨è¿‡çš„å·¥å…·ã€‘
{', '.join(used_tools) if used_tools else 'æ— '}

ã€å¯ç”¨å·¥å…·åˆ—è¡¨ã€‘
{available_tools}

è¯·æ ¹æ®å½“å‰è¯Šæ–­è¿›åº¦ï¼Œé€‰æ‹©ä¸‹ä¸€æ­¥æœ€åˆé€‚çš„å·¥å…·ã€‚

é€‰æ‹©è¦æ±‚ï¼š
1. å·¥å…·å¿…é¡»ä»ã€å¯ç”¨å·¥å…·åˆ—è¡¨ã€‘ä¸­é€‰æ‹©
2. å¯ä»¥é‡å¤ä½¿ç”¨å·²ç”¨è¿‡çš„å·¥å…·ï¼ˆå¦‚éœ€å¤šæ¬¡æŸ¥è¯¢ï¼‰
3. ä¼˜å…ˆé€‰æ‹©èƒ½æ¨è¿›è¯Šæ–­ã€è·å–å…³é”®ä¿¡æ¯çš„å·¥å…·
4. è€ƒè™‘è¯Šæ–­çš„é€»è¾‘é¡ºåºå’Œå› æœå…³ç³»
5. å¦‚æœå·²æœ‰è¶³å¤Ÿä¿¡æ¯å¯ä»¥å¾—å‡ºç»“è®ºï¼Œé€‰æ‹©èƒ½éªŒè¯æˆ–è¡¥å……ç»“è®ºçš„å·¥å…·
6. **é‡è¦ï¼šå¡«å†™tool_requestå‚æ•°æ—¶ï¼Œè¯·æ ¹æ®ã€ç›¸å…³å‚æ•°ã€‘ä¸­çš„ä¿¡æ¯å¡«å†™å‡†ç¡®çš„è®¾å¤‡åã€æ¥å£åç­‰**

ä»¥JSONæ ¼å¼è¾“å‡ºï¼ˆåªè¾“å‡ºJSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼‰ï¼š
```json
{{
  "tool_name": "ä»å¯ç”¨å·¥å…·åˆ—è¡¨ä¸­é€‰æ‹©çš„å·¥å…·åç§°",
  "tool_request": {{
    "device_name": "è®¾å¤‡åï¼ˆå‚è€ƒä¸Šé¢çš„å‚æ•°ä¿¡æ¯ï¼‰",
    "interface_name": "æ¥å£åï¼ˆå‚è€ƒä¸Šé¢çš„å‚æ•°ä¿¡æ¯ï¼‰",
    "å…¶ä»–å‚æ•°": "æ ¹æ®å·¥å…·éœ€è¦å¡«å†™"
  }},
  "reasoning": "ä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·ï¼ŒæœŸæœ›è§£å†³ä»€ä¹ˆé—®é¢˜",
  "expected_info": "æœŸæœ›ä»è¿™ä¸ªå·¥å…·è·å¾—ä»€ä¹ˆä¿¡æ¯"
}}
```

æ³¨æ„ï¼š
- tool_nameå¿…é¡»ç²¾ç¡®åŒ¹é…å·¥å…·åˆ—è¡¨ä¸­çš„åç§°
- tool_requestä¸­çš„device_nameå’Œinterface_nameç­‰å‚æ•°è¯·ä½¿ç”¨ã€ç›¸å…³å‚æ•°ã€‘ä¸­æä¾›çš„å‡†ç¡®å€¼
- å¦‚æœå·¥å…·éœ€è¦å…¶ä»–å‚æ•°ï¼Œæ ¹æ®è¯Šæ–­ä¸Šä¸‹æ–‡åˆç†å¡«å†™
- reasoningè¦ç®€æ´æ˜äº†
"""
        return prompt
    
    def _format_context_params(self, context_params: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–context_paramsä¸ºæ˜“è¯»çš„ã€ç›¸å…³å‚æ•°ã€‘éƒ¨åˆ†
        
        Args:
            context_params: ä»mock_dataæå–çš„å‚æ•°å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
        """
        if not context_params:
            return ""
        
        # å‚æ•°åç§°æ˜ å°„ï¼ˆä¸­æ–‡ï¼‰
        param_names = {
            'device_name': 'è®¾å¤‡å',
            'device': 'è®¾å¤‡å',
            'interface_name': 'æ¥å£å',
            'interface': 'æ¥å£å',
            'port': 'ç«¯å£',
            'vlan': 'VLAN',
            'ip': 'IPåœ°å€',
            'hostname': 'ä¸»æœºå',
            'start_time': 'å¼€å§‹æ—¶é—´',
            'end_time': 'ç»“æŸæ—¶é—´',
            'filter_condition1': 'è¿‡æ»¤æ¡ä»¶1',
            'filter_condition2': 'è¿‡æ»¤æ¡ä»¶2',
        }
        
        lines = ["ã€ç›¸å…³å‚æ•°ã€‘ï¼ˆå·¥å…·è°ƒç”¨æ—¶è¯·ä½¿ç”¨è¿™äº›å‚æ•°ï¼‰"]
        
        for key, value in context_params.items():
            # è·å–ä¸­æ–‡åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸkey
            display_name = param_names.get(key, key)
            lines.append(f"{display_name}: {value}")
        
        return '\n'.join(lines)
    
    def _format_entities(self, entities: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–entitiesä¿¡æ¯
        
        Args:
            entities: å®ä½“å­—å…¸ï¼Œå¦‚ {"device": "serverleaf01", "interface": "10GE1/0/24"}
            
        Returns:
            æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
        """
        if not entities:
            return "æ— ç‰¹å®šå®ä½“ä¿¡æ¯"
        
        lines = []
        
        # å¸¸è§çš„å®ä½“ç±»å‹åŠå…¶ä¸­æ–‡åç§°
        entity_names = {
            'device': 'è®¾å¤‡å',
            'device_name': 'è®¾å¤‡å',
            'interface': 'æ¥å£å',
            'interface_name': 'æ¥å£å',
            'port': 'ç«¯å£',
            'vlan': 'VLAN',
            'ip': 'IPåœ°å€',
            'hostname': 'ä¸»æœºå',
        }
        
        for key, value in entities.items():
            # è·å–ä¸­æ–‡åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸkey
            display_name = entity_names.get(key, key)
            lines.append(f"{display_name}: {value}")
        
        return '\n'.join(lines) if lines else "æ— ç‰¹å®šå®ä½“ä¿¡æ¯"
    
    def _get_tool_candidates(self, prompt: str, temperature: float, top_k: int = 3) -> List[Dict]:
        """
        è°ƒç”¨LLMè·å–å€™é€‰å·¥å…·
        
        Args:
            prompt: è§„åˆ’prompt
            temperature: æ¸©åº¦å‚æ•°
            top_k: è¿”å›top Kä¸ªå€™é€‰
            
        Returns:
            å€™é€‰å·¥å…·åˆ—è¡¨
        """
        candidates = []
        
        try:
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.api_base
            )
            
            # è°ƒç”¨å¤šæ¬¡ä»¥è·å–å¤šä¸ªå€™é€‰
            for i in range(top_k):
                response = client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªç½‘ç»œæ•…éšœè¯Šæ–­ä¸“å®¶ï¼Œæ“…é•¿é€‰æ‹©åˆé€‚çš„è¯Šæ–­å·¥å…·ã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    temperature=temperature + i * 0.1,  # é€æ¸å¢åŠ æ¸©åº¦ä»¥è·å¾—å¤šæ ·æ€§
                    max_tokens=500
                )
                
                result_text = response.choices[0].message.content
                
                # è§£æJSON
                candidate = self._parse_json_response(result_text)
                
                if candidate and 'tool_name' in candidate:
                    # éªŒè¯å·¥å…·æ˜¯å¦æœ‰æ•ˆ
                    if self.tool_manager.is_valid_tool(candidate['tool_name']):
                        candidates.append(candidate)
                    else:
                        print(f"  âš ï¸  LLMç”Ÿæˆäº†æ— æ•ˆå·¥å…·: {candidate.get('tool_name')}")
            
            return candidates
            
        except Exception as e:
            print(f"è§„åˆ’å™¨è°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """è§£æLLMè¿”å›çš„JSON"""
        try:
            # æå–JSONä»£ç å—
            if '```json' in response:
                json_start = response.find('```json') + 7
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            elif '```' in response:
                json_start = response.find('```') + 3
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            else:
                json_str = response.strip()
            
            return json.loads(json_str)
        except Exception as e:
            print(f"è§£æJSONå¤±è´¥: {e}")
            return {}
    
    def _apply_exploration_strategy(self, candidates: List[Dict], state: StateManager) -> Dict:
        """
        åº”ç”¨explorationç­–ç•¥é€‰æ‹©æœ€ç»ˆå·¥å…·
        
        Args:
            candidates: å€™é€‰å·¥å…·åˆ—è¡¨
            state: å½“å‰çŠ¶æ€
            
        Returns:
            é€‰ä¸­çš„å·¥å…·
        """
        if not candidates:
            return {"error": "æ— å€™é€‰å·¥å…·"}
        
        # ç»™æ¯ä¸ªå€™é€‰æ‰“åˆ†
        for candidate in candidates:
            tool_name = candidate['tool_name']
            
            # åŸºç¡€åˆ†æ•°ï¼ˆå‡è®¾LLMè¿”å›çš„é¡ºåºä»£è¡¨è´¨é‡ï¼‰
            base_score = len(candidates) - candidates.index(candidate)
            
            # Exploration bonus: å°‘ç”¨çš„å·¥å…·åŠ åˆ†
            usage_count = state.get_tool_usage_count(tool_name)
            exploration_bonus = 2.0 / (usage_count + 1)  # ç”¨å¾—è¶Šå°‘ï¼Œbonusè¶Šé«˜
            
            # æ€»åˆ†
            candidate['score'] = base_score + exploration_bonus
        
        # æ ¹æ®exploration_modeé€‰æ‹©
        if self.exploration_mode == 'greedy':
            # æ€»æ˜¯é€‰æ‹©å¾—åˆ†æœ€é«˜çš„
            candidates.sort(key=lambda x: x['score'], reverse=True)
            selected = candidates[0]
            
        elif self.exploration_mode == 'balanced':
            # 70%é€‰top1, 30%ä»top2å’Œtop3ä¸­éšæœºé€‰
            candidates.sort(key=lambda x: x['score'], reverse=True)
            if random.random() < 0.7:
                selected = candidates[0]
            else:
                selected = random.choice(candidates[1:]) if len(candidates) > 1 else candidates[0]
        
        else:  # exploratory
            # æ ¹æ®åˆ†æ•°è¿›è¡ŒåŠ æƒéšæœºé€‰æ‹©
            candidates.sort(key=lambda x: x['score'], reverse=True)
            weights = [c['score'] for c in candidates]
            selected = random.choices(candidates, weights=weights, k=1)[0]
        
        print(f"  ğŸ“ é€‰æ‹©æ¨¡å¼: {self.exploration_mode}")
        print(f"  ğŸ¯ é€‰ä¸­å·¥å…·: {selected['tool_name']}")
        print(f"  ğŸ’­ ç†ç”±: {selected.get('reasoning', 'æ— ')}")
        
        return selected
    
    def set_exploration_mode(self, mode: str):
        """
        è®¾ç½®æ¢ç´¢æ¨¡å¼
        
        Args:
            mode: 'greedy', 'balanced', 'exploratory'
        """
        if mode in ['greedy', 'balanced', 'exploratory']:
            self.exploration_mode = mode
        else:
            print(f"âš ï¸  æ— æ•ˆçš„æ¢ç´¢æ¨¡å¼: {mode}ï¼Œä¿æŒå½“å‰æ¨¡å¼: {self.exploration_mode}")


def test_enhanced_planner():
    """æµ‹è¯•å¢å¼ºè§„åˆ’å™¨"""
    print("=" * 80)
    print("æµ‹è¯•å¢å¼ºè§„åˆ’å™¨")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç»„ä»¶
    from tool_manager import ToolManager
    
    tool_manager = ToolManager('/mnt/user-data/outputs/available_tools.txt')
    
    planner = EnhancedPlanner(
        tool_manager=tool_manager,
        api_key="kw-qIdb2KBfLLBkk6YEJ1clWKKOctnHgWMjtfRJwQ2yTLBCXjMv",
        api_base="http://10.12.208.86:8502",
        exploration_mode='balanced'
    )
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    state = StateManager()
    
    # åˆ›å»ºæµ‹è¯•ç›®æ ‡
    goal = {
        "main_goal": "æ‰¾å‡ºå¯¼è‡´ä¸¢åŒ…çš„åŸå› ",
        "problem_type": "ä¸¢åŒ…",
        "key_aspects": ["æ¥å£çŠ¶æ€", "æµé‡åˆ†æ", "é”™è¯¯ç»Ÿè®¡"],
        "entities": {
            "device": "serverleaf01_1_16.135",
            "interface": "10GE1/0/24"
        }
    }
    
    # æµ‹è¯•é€‰æ‹©å·¥å…·
    print("\næµ‹è¯•å·¥å…·é€‰æ‹©ï¼ˆ3æ¬¡ï¼‰ï¼š")
    print("-" * 80)
    
    for i in range(3):
        print(f"\nç¬¬ {i+1} æ¬¡é€‰æ‹©:")
        
        plan = planner.select_next_tool(state, goal, temperature=0.7)
        
        if 'error' in plan:
            print(f"âŒ é”™è¯¯: {plan['error']}")
        else:
            print(f"âœ… å·¥å…·: {plan['tool_name']}")
            print(f"   å‚æ•°: {json.dumps(plan['tool_request'], ensure_ascii=False)}")
            
            # æ¨¡æ‹Ÿæ‰§è¡Œ
            state.add_execution(
                plan['tool_name'],
                plan['tool_request'],
                {"mock": "response"},
                plan.get('reasoning', '')
            )
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    test_enhanced_planner()
