"""
å¢å¼ºè§„åˆ’å™¨ï¼ˆEnhanced Plannerï¼‰
æ”¯æŒè‡ªç”±æ¢ç´¢å’Œå¤šæ ·åŒ–çš„å·¥å…·é€‰æ‹©ç­–ç•¥
"""

import json
import openai
import random
from typing import Dict, List, Any, Optional
from tool_manager import ToolManager
from state_manager import StateManager


class EnhancedPlanner:
    """å¢å¼ºè§„åˆ’å™¨ - æ”¯æŒå¤šæ ·åŒ–æ¢ç´¢"""
    
    def __init__(self, tool_manager: ToolManager, 
                 api_key: str, 
                 api_base: str = None,
                 model: str = "gpt-4o-mini",
                 exploration_mode: str = 'balanced'):
        """
        åˆå§‹åŒ–å¢å¼ºè§„åˆ’å™¨
        
        Args:
            tool_manager: å·¥å…·ç®¡ç†å™¨
            api_key: APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model: æ¨¡å‹åç§°
            exploration_mode: æ¢ç´¢æ¨¡å¼ ('greedy', 'balanced', 'exploratory')
        """
        self.tool_manager = tool_manager
        self.api_key = api_key
        self.api_base = api_base or "http://10.12.208.86:8502"
        self.model = model
        self.exploration_mode = exploration_mode
    
    def select_next_tool(self, state: StateManager, goal: Dict[str, Any], 
                        temperature: float = 0.7, known_entities: Dict[str, List[str]] = None) -> Dict[str, Any]:
        """
        é€‰æ‹©ä¸‹ä¸€æ­¥è¦ä½¿ç”¨çš„å·¥å…·
        
        Args:
            state: å½“å‰çŠ¶æ€
            goal: è¯Šæ–­ç›®æ ‡
            temperature: æ¸©åº¦å‚æ•°ï¼ˆæ§åˆ¶éšæœºæ€§ï¼‰
            known_entities: å·²çŸ¥å®ä½“åˆ—è¡¨ï¼Œå¦‚{'interfaces': ['eth0', 'eth1']}
            
        Returns:
            {
                "tool_name": "å·¥å…·åç§°",
                "tool_request": {...},
                "reasoning": "é€‰æ‹©ç†ç”±",
                "expected_info": "æœŸæœ›ä¿¡æ¯"
            }
        """
        # 1. ç”Ÿæˆprompt
        prompt = self._generate_planning_prompt(state, goal, known_entities)
        
        # 2. è°ƒç”¨LLMè·å–å€™é€‰å·¥å…·
        candidates = self._get_tool_candidates(prompt, temperature, top_k=3)
        
        if not candidates:
            return {"error": "æœªèƒ½ç”Ÿæˆå·¥å…·é€‰æ‹©"}
        
        # 3. åº”ç”¨explorationç­–ç•¥é€‰æ‹©æœ€ç»ˆå·¥å…·
        selected = self._apply_exploration_strategy(candidates, state)
        
        return selected
    
    def _generate_planning_prompt(self, state: StateManager, goal: Dict[str, Any], known_entities: Dict[str, List[str]] = None) -> str:
        """ç”Ÿæˆè§„åˆ’prompt"""
        
        # è·å–è¯Šæ–­ä¸Šä¸‹æ–‡
        diagnostic_context = state.get_diagnostic_context()
        
        # è·å–è¯Šæ–­é€»è¾‘é“¾
        diagnostic_chain = state.format_diagnostic_chain()
        
        # æ ¼å¼åŒ–å‘ç°
        findings = state.format_findings()
        
        # å·²ä½¿ç”¨çš„å·¥å…·ï¼ˆç”¨äºå‚è€ƒï¼‰
        used_tools = list(state.tool_usage_count.keys())
        
        # æå–context_paramsï¼ˆä»mock_dataæå–çš„å‚æ•°ï¼‰
        context_params = goal.get('context_params', {})
        
        # æ ¼å¼åŒ–å‚æ•°ä¿¡æ¯
        params_section = ""
        if context_params:
            params_section = self._format_context_params(context_params)
        
        # æ ¼å¼åŒ–å·²çŸ¥å®ä½“åˆ—è¡¨
        entities_section = ""
        if known_entities:
            entities_lines = []
            for entity_type, entities in known_entities.items():
                if entities:
                    entities_lines.append(f"  {entity_type}: {', '.join(entities)}")
            if entities_lines:
                entities_section = f"""
ã€å·²çŸ¥å®ä½“åˆ—è¡¨ã€‘
{chr(10).join(entities_lines)}

**é‡è¦æç¤ºï¼šå¦‚æœéœ€è¦å¯¹ä¸Šè¿°å¤šä¸ªå®ä½“æ‰§è¡Œç›¸åŒçš„æ“ä½œï¼ˆä¾‹å¦‚é€ä¸€æ£€æŸ¥æ¯ä¸ªæ¥å£çš„çŠ¶æ€ï¼‰ï¼Œè¯·åœ¨reasoningä¸­æ˜ç¡®è¯´æ˜ã€‚ç³»ç»Ÿä¼šè‡ªåŠ¨å¯¹æ‰€æœ‰å®ä½“æ‰¹é‡æ‰§è¡Œè¯¥æ“ä½œï¼Œä½ åªéœ€è¦åœ¨tool_requestä¸­å¡«å†™ä¸€ä¸ªç¤ºä¾‹å³å¯ã€‚**
"""
        
        # è·å–æœ€åä¸€æ­¥çš„å·¥å…·å’Œç»“æœï¼ˆç”¨äºå¼ºè°ƒè¿ç»­æ€§ï¼‰
        last_step_info = ""
        if state.executed_tools:
            last_tool = state.executed_tools[-1]
            last_step_info = f"""
ã€ä¸Šä¸€æ­¥æ‰§è¡Œç»“æœã€‘
å·¥å…·: {last_tool['tool_name']}
é€‰æ‹©åŸå› : {last_tool.get('reasoning', 'æœªè®°å½•')}
è§‚å¯Ÿç»“æœ: {json.dumps(last_tool['tool_response'], ensure_ascii=False)[:200]}...
"""
        
        # è·å–è¯¦ç»†çš„å·¥å…·åˆ—è¡¨ï¼ˆåŒ…å«å‚æ•°å­—ç¬¦ä¸²ï¼‰
        available_tools_detailed = self.tool_manager.get_tools_with_parameters()
        
        prompt = f"""ä½ æ˜¯ä¸€ä¸ªç½‘ç»œæ•…éšœè¯Šæ–­ä¸“å®¶ï¼Œæ­£åœ¨è¿›è¡Œæ•…éšœæ’æŸ¥ã€‚ä½ éœ€è¦åŸºäºå·²æœ‰çš„è¯Šæ–­ç»“æœï¼Œé€»è¾‘æ¸…æ™°åœ°é€‰æ‹©ä¸‹ä¸€æ­¥ã€‚

ã€è¯Šæ–­ç›®æ ‡ã€‘
ä¸»è¦ç›®æ ‡: {goal.get('main_goal', 'æœªçŸ¥')}
é—®é¢˜ç±»å‹: {goal.get('problem_type', 'æœªçŸ¥')}
éœ€è¦å…³æ³¨çš„æ–¹é¢: {', '.join(goal.get('key_aspects', []))}

{params_section}

ã€è¯Šæ–­ä¸Šä¸‹æ–‡ã€‘
{diagnostic_context}
{last_step_info}
{entities_section}

ã€è¯Šæ–­é€»è¾‘é“¾ã€‘
{diagnostic_chain if diagnostic_chain != "æš‚æ— è¯Šæ–­é€»è¾‘é“¾" else "è¿™æ˜¯ç¬¬ä¸€æ­¥ï¼Œå¼€å§‹è¯Šæ–­"}

ã€å½“å‰å‘ç°ã€‘
{findings}

ã€å·²ä½¿ç”¨è¿‡çš„å·¥å…·ã€‘
{', '.join(used_tools) if used_tools else 'æ— '}

ã€å¯ç”¨å·¥å…·åŠå‚æ•°ã€‘
{available_tools_detailed}

è¯·æ ¹æ®ä¸Šè¿°ä¿¡æ¯ï¼Œé€‰æ‹©ä¸‹ä¸€æ­¥æœ€åˆé€‚çš„å·¥å…·ã€‚

**å…³é”®è¦æ±‚ï¼š**
1. **åŸºäºé€»è¾‘æ¨ç†**ï¼šæ ¹æ®å·²æœ‰çš„è§‚å¯Ÿç»“æœå’Œç»“è®ºï¼Œè§£é‡Šä¸ºä»€ä¹ˆé€‰æ‹©è¿™ä¸ªå·¥å…·
2. **å‚æ•°å‡†ç¡®**ï¼šä¸¥æ ¼æŒ‰ç…§å·¥å…·çš„Parameterså®šä¹‰å¡«å†™tool_requestï¼Œä»ã€ç›¸å…³å‚æ•°ã€‘å’Œã€å·²çŸ¥å®ä½“åˆ—è¡¨ã€‘ä¸­è·å–å‡†ç¡®çš„å€¼
3. **è¿è´¯æ€§**ï¼šè¯´æ˜è¿™ä¸€æ­¥å¦‚ä½•æ‰¿æ¥ä¸Šä¸€æ­¥çš„å‘ç°ï¼ŒæœŸæœ›éªŒè¯æˆ–æ’é™¤ä»€ä¹ˆ
4. **Parametersæ ¼å¼**ï¼šæ¯ä¸ªå·¥å…·ä¸‹é¢çš„Parametersè¡Œå®šä¹‰äº†è¯¥å·¥å…·éœ€è¦çš„å‚æ•°ï¼Œè¯·ä»”ç»†é˜…è¯»å¹¶æŒ‰æ ¼å¼å¡«å†™
5. **é¿å…é‡å¤**ï¼šä¸è¦å¯¹åŒä¸€ä¸ªå·¥å…·å’ŒåŒä¸€ç»„å‚æ•°å¤šæ¬¡è°ƒç”¨è·å–ç›¸åŒä¿¡æ¯ã€‚å¦‚æœå·²ç»è·å–è¿‡ä¿¡æ¯ï¼Œåº”è¯¥åŸºäºå·²æœ‰ä¿¡æ¯è¿›è¡Œä¸‹ä¸€æ­¥æ¨ç†
6. **æ‰¹é‡æ“ä½œ**ï¼šå¦‚æœéœ€è¦å¯¹ã€å·²çŸ¥å®ä½“åˆ—è¡¨ã€‘ä¸­çš„å¤šä¸ªå®ä½“æ‰§è¡Œç›¸åŒæ“ä½œï¼Œåœ¨reasoningä¸­ç”¨"é€ä¸€"ã€"æ¯ä¸ª"ã€"æ‰€æœ‰"ç­‰è¯æ˜ç¡®è¯´æ˜å³å¯

ä»¥JSONæ ¼å¼è¾“å‡ºï¼ˆåªè¾“å‡ºJSONï¼Œä¸è¦æœ‰å…¶ä»–æ–‡å­—ï¼‰ï¼š
```json
{{
  "tool_name": "å·¥å…·åç§°ï¼ˆå¿…é¡»ä»ä¸Šé¢çš„å·¥å…·åˆ—è¡¨ä¸­ç²¾ç¡®é€‰æ‹©ï¼‰",
  "tool_request": {{
    "å‚æ•°å1": "å‚æ•°å€¼1ï¼ˆæ ¹æ®å·¥å…·Parameterså®šä¹‰å¡«å†™ï¼‰",
    "å‚æ•°å2": "å‚æ•°å€¼2"
  }},
  "reasoning": "é€‰æ‹©æ­¤å·¥å…·çš„åŸå› ï¼šåŸºäºä¸Šä¸€æ­¥çš„XXXå‘ç°ï¼Œéœ€è¦éªŒè¯/æ’é™¤YYYï¼Œå› æ­¤é€‰æ‹©æ­¤å·¥å…·ã€‚å¦‚æœæ˜¯æ‰¹é‡æ“ä½œï¼Œè¯´æ˜'é€ä¸€æ£€æŸ¥æ‰€æœ‰XXX'",
  "expected_outcome": "æœŸæœ›ç»“æœï¼šå¦‚æœå‘ç°Aï¼Œè¯´æ˜...; å¦‚æœå‘ç°Bï¼Œè¯´æ˜...",
  "next_focus": "æ‰§è¡Œåçš„ä¸‹ä¸€æ­¥ç„¦ç‚¹ï¼ˆå¦‚æœå‘ç°é—®é¢˜ï¼Œä¸‹ä¸€æ­¥åº”å…³æ³¨ä»€ä¹ˆï¼‰"
}}
```

æ³¨æ„ï¼š
- reasoningå¿…é¡»è¯´æ˜ä¸ä¹‹å‰æ­¥éª¤çš„é€»è¾‘å…³ç³»
- å¦‚æœæ˜¯æ‰¹é‡æ“ä½œï¼Œreasoningä¸­ç”¨"é€ä¸€"ã€"æ¯ä¸ª"ã€"æ‰€æœ‰"ç­‰è¯æ˜ç¡®è¯´æ˜
- expected_outcomeè¦æ˜ç¡®æœŸæœ›éªŒè¯ä»€ä¹ˆå‡è®¾
- next_focuså¸®åŠ©ç»´æŠ¤è¯Šæ–­çš„è¿è´¯æ€§
- tool_requestçš„å‚æ•°åå’Œå‚æ•°å€¼è¦æ ¹æ®Parameterså®šä¹‰å¡«å†™
- é¿å…é‡å¤è°ƒç”¨å·²ç»æ‰§è¡Œè¿‡çš„å·¥å…·è·å–ç›¸åŒä¿¡æ¯
"""
        return prompt
    
    def _format_context_params(self, context_params: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–context_paramsä¸ºæ˜“è¯»çš„ã€ç›¸å…³å‚æ•°ã€‘éƒ¨åˆ†
        
        Args:
            context_params: ä»mock_dataæå–çš„å‚æ•°å­—å…¸
            
        Returns:
            æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
        """
        if not context_params:
            return ""
        
        # å‚æ•°åç§°æ˜ å°„ï¼ˆä¸­æ–‡ï¼‰
        param_names = {
            'device_name': 'è®¾å¤‡å',
            'device': 'è®¾å¤‡å',
            'interface_name': 'æ¥å£å',
            'interface': 'æ¥å£å',
            'port': 'ç«¯å£',
            'vlan': 'VLAN',
            'ip': 'IPåœ°å€',
            'hostname': 'ä¸»æœºå',
            'start_time': 'å¼€å§‹æ—¶é—´',
            'end_time': 'ç»“æŸæ—¶é—´',
            'filter_condition1': 'è¿‡æ»¤æ¡ä»¶1',
            'filter_condition2': 'è¿‡æ»¤æ¡ä»¶2',
        }
        
        lines = ["ã€ç›¸å…³å‚æ•°ã€‘ï¼ˆå·¥å…·è°ƒç”¨æ—¶è¯·ä½¿ç”¨è¿™äº›å‚æ•°ï¼‰"]
        
        for key, value in context_params.items():
            # è·å–ä¸­æ–‡åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸkey
            display_name = param_names.get(key, key)
            lines.append(f"{display_name}: {value}")
        
        return '\n'.join(lines)
    
    def _format_entities(self, entities: Dict[str, Any]) -> str:
        """
        æ ¼å¼åŒ–entitiesä¿¡æ¯
        
        Args:
            entities: å®ä½“å­—å…¸ï¼Œå¦‚ {"device": "serverleaf01", "interface": "10GE1/0/24"}
            
        Returns:
            æ ¼å¼åŒ–çš„å­—ç¬¦ä¸²
        """
        if not entities:
            return "æ— ç‰¹å®šå®ä½“ä¿¡æ¯"
        
        lines = []
        
        # å¸¸è§çš„å®ä½“ç±»å‹åŠå…¶ä¸­æ–‡åç§°
        entity_names = {
            'device': 'è®¾å¤‡å',
            'device_name': 'è®¾å¤‡å',
            'interface': 'æ¥å£å',
            'interface_name': 'æ¥å£å',
            'port': 'ç«¯å£',
            'vlan': 'VLAN',
            'ip': 'IPåœ°å€',
            'hostname': 'ä¸»æœºå',
        }
        
        for key, value in entities.items():
            # è·å–ä¸­æ–‡åç§°ï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸkey
            display_name = entity_names.get(key, key)
            lines.append(f"{display_name}: {value}")
        
        return '\n'.join(lines) if lines else "æ— ç‰¹å®šå®ä½“ä¿¡æ¯"
    
    def _get_tool_candidates(self, prompt: str, temperature: float, top_k: int = 3) -> List[Dict]:
        """
        è°ƒç”¨LLMè·å–å€™é€‰å·¥å…·
        
        Args:
            prompt: è§„åˆ’prompt
            temperature: æ¸©åº¦å‚æ•°
            top_k: è¿”å›top Kä¸ªå€™é€‰
            
        Returns:
            å€™é€‰å·¥å…·åˆ—è¡¨
        """
        candidates = []
        
        try:
            client = openai.OpenAI(
                api_key=self.api_key,
                base_url=self.api_base
            )
            
            # è°ƒç”¨å¤šæ¬¡ä»¥è·å–å¤šä¸ªå€™é€‰
            for i in range(top_k):
                response = client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {
                            "role": "system",
                            "content": "ä½ æ˜¯ä¸€ä¸ªç½‘ç»œæ•…éšœè¯Šæ–­ä¸“å®¶ï¼Œæ“…é•¿é€‰æ‹©åˆé€‚çš„è¯Šæ–­å·¥å…·ã€‚"
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    temperature=temperature + i * 0.1,  # é€æ¸å¢åŠ æ¸©åº¦ä»¥è·å¾—å¤šæ ·æ€§
                    max_tokens=500
                )
                
                result_text = response.choices[0].message.content
                
                # è§£æJSON
                candidate = self._parse_json_response(result_text)
                
                if candidate and 'tool_name' in candidate:
                    # éªŒè¯å·¥å…·æ˜¯å¦æœ‰æ•ˆ
                    if self.tool_manager.is_valid_tool(candidate['tool_name']):
                        candidates.append(candidate)
                    else:
                        print(f"  âš ï¸  LLMç”Ÿæˆäº†æ— æ•ˆå·¥å…·: {candidate.get('tool_name')}")
            
            return candidates
            
        except Exception as e:
            print(f"è§„åˆ’å™¨è°ƒç”¨å¤±è´¥: {e}")
            return []
    
    def _parse_json_response(self, response: str) -> Dict[str, Any]:
        """è§£æLLMè¿”å›çš„JSON"""
        try:
            # æå–JSONä»£ç å—
            if '```json' in response:
                json_start = response.find('```json') + 7
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            elif '```' in response:
                json_start = response.find('```') + 3
                json_end = response.find('```', json_start)
                json_str = response[json_start:json_end].strip()
            else:
                json_str = response.strip()
            
            return json.loads(json_str)
        except Exception as e:
            print(f"è§£æJSONå¤±è´¥: {e}")
            return {}
    
    def _apply_exploration_strategy(self, candidates: List[Dict], state: StateManager) -> Dict:
        """
        åº”ç”¨explorationç­–ç•¥é€‰æ‹©æœ€ç»ˆå·¥å…·
        
        Args:
            candidates: å€™é€‰å·¥å…·åˆ—è¡¨
            state: å½“å‰çŠ¶æ€
            
        Returns:
            é€‰ä¸­çš„å·¥å…·
        """
        if not candidates:
            return {"error": "æ— å€™é€‰å·¥å…·"}
        
        # ç»™æ¯ä¸ªå€™é€‰æ‰“åˆ†
        for candidate in candidates:
            tool_name = candidate['tool_name']
            
            # åŸºç¡€åˆ†æ•°ï¼ˆå‡è®¾LLMè¿”å›çš„é¡ºåºä»£è¡¨è´¨é‡ï¼‰
            base_score = len(candidates) - candidates.index(candidate)
            
            # Exploration bonus: å°‘ç”¨çš„å·¥å…·åŠ åˆ†
            usage_count = state.get_tool_usage_count(tool_name)
            exploration_bonus = 2.0 / (usage_count + 1)  # ç”¨å¾—è¶Šå°‘ï¼Œbonusè¶Šé«˜
            
            # æ€»åˆ†
            candidate['score'] = base_score + exploration_bonus
        
        # æ ¹æ®exploration_modeé€‰æ‹©
        if self.exploration_mode == 'greedy':
            # æ€»æ˜¯é€‰æ‹©å¾—åˆ†æœ€é«˜çš„
            candidates.sort(key=lambda x: x['score'], reverse=True)
            selected = candidates[0]
            
        elif self.exploration_mode == 'balanced':
            # 70%é€‰top1, 30%ä»top2å’Œtop3ä¸­éšæœºé€‰
            candidates.sort(key=lambda x: x['score'], reverse=True)
            if random.random() < 0.7:
                selected = candidates[0]
            else:
                selected = random.choice(candidates[1:]) if len(candidates) > 1 else candidates[0]
        
        else:  # exploratory
            # æ ¹æ®åˆ†æ•°è¿›è¡ŒåŠ æƒéšæœºé€‰æ‹©
            candidates.sort(key=lambda x: x['score'], reverse=True)
            weights = [c['score'] for c in candidates]
            selected = random.choices(candidates, weights=weights, k=1)[0]
        
        print(f"  ğŸ“ é€‰æ‹©æ¨¡å¼: {self.exploration_mode}")
        print(f"  ğŸ¯ é€‰ä¸­å·¥å…·: {selected['tool_name']}")
        print(f"  ğŸ’­ ç†ç”±: {selected.get('reasoning', 'æ— ')}")
        
        return selected
    
    def set_exploration_mode(self, mode: str):
        """
        è®¾ç½®æ¢ç´¢æ¨¡å¼
        
        Args:
            mode: 'greedy', 'balanced', 'exploratory'
        """
        if mode in ['greedy', 'balanced', 'exploratory']:
            self.exploration_mode = mode
        else:
            print(f"âš ï¸  æ— æ•ˆçš„æ¢ç´¢æ¨¡å¼: {mode}ï¼Œä¿æŒå½“å‰æ¨¡å¼: {self.exploration_mode}")


def test_enhanced_planner():
    """æµ‹è¯•å¢å¼ºè§„åˆ’å™¨"""
    print("=" * 80)
    print("æµ‹è¯•å¢å¼ºè§„åˆ’å™¨")
    print("=" * 80)
    
    # åˆå§‹åŒ–ç»„ä»¶
    from tool_manager import ToolManager
    
    tool_manager = ToolManager('/mnt/user-data/outputs/available_tools.txt')
    
    planner = EnhancedPlanner(
        tool_manager=tool_manager,
        api_key="kw-qIdb2KBfLLBkk6YEJ1clWKKOctnHgWMjtfRJwQ2yTLBCXjMv",
        api_base="http://10.12.208.86:8502",
        exploration_mode='balanced'
    )
    
    # åˆ›å»ºæµ‹è¯•çŠ¶æ€
    state = StateManager()
    
    # åˆ›å»ºæµ‹è¯•ç›®æ ‡
    goal = {
        "main_goal": "æ‰¾å‡ºå¯¼è‡´ä¸¢åŒ…çš„åŸå› ",
        "problem_type": "ä¸¢åŒ…",
        "key_aspects": ["æ¥å£çŠ¶æ€", "æµé‡åˆ†æ", "é”™è¯¯ç»Ÿè®¡"],
        "entities": {
            "device": "serverleaf01_1_16.135",
            "interface": "10GE1/0/24"
        }
    }
    
    # æµ‹è¯•é€‰æ‹©å·¥å…·
    print("\næµ‹è¯•å·¥å…·é€‰æ‹©ï¼ˆ3æ¬¡ï¼‰ï¼š")
    print("-" * 80)
    
    for i in range(3):
        print(f"\nç¬¬ {i+1} æ¬¡é€‰æ‹©:")
        
        plan = planner.select_next_tool(state, goal, temperature=0.7)
        
        if 'error' in plan:
            print(f"âŒ é”™è¯¯: {plan['error']}")
        else:
            print(f"âœ… å·¥å…·: {plan['tool_name']}")
            print(f"   å‚æ•°: {json.dumps(plan['tool_request'], ensure_ascii=False)}")
            
            # æ¨¡æ‹Ÿæ‰§è¡Œ
            state.add_execution(
                plan['tool_name'],
                plan['tool_request'],
                {"mock": "response"},
                plan.get('reasoning', '')
            )
    
    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")
    print("=" * 80)


if __name__ == '__main__':
    test_enhanced_planner()
